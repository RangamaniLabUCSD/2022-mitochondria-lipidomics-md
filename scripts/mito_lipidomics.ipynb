{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b9284b-ceef-492f-b74e-9d08f77cc17f",
   "metadata": {},
   "source": [
    "# Analysis of material properties of mitochondrial membranes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba281424-90c8-460a-869f-425a2cf33323",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d158fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98cba19-8b79-44a2-b05a-37d9638da0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib Version: 3.6.2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%autoreload 1\n",
    "import pickle\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import MDAnalysis\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.typing as npt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import integrate, interpolate, stats\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "%aimport util\n",
    "from plot_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfcc1e19-ebee-4b37-bcc5-c04937953f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_averaging(power2D, mc, min_bin=0.001, max_bin=1, bin_width=0.001):\n",
    "    \"\"\"\n",
    "    Radially average the power spectrum to obtain values. Notably the natural freqeuncy unit\n",
    "    of this function is A^-1.\n",
    "\n",
    "    Args:\n",
    "        power2D (numpy.array((N,N))): Power spectrum\n",
    "        mc (_type_): Membrane curvature object with metadata\n",
    "        min_bin (float, optional): Minimum bin value. Defaults to 0.001.\n",
    "        max_bin (int, optional): Maximum bin value. Defaults to 1.\n",
    "        bin_width (float, optional): Bin width. Defaults to 0.001.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Binned power spectra\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(mc['qx'], mc['qy'])  # A^-1\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    bins = np.arange(min_bin, max_bin, bin_width)\n",
    "\n",
    "    digitized = np.digitize(r, bins)\n",
    "    bc = np.array(\n",
    "        [\n",
    "            r[digitized == i].mean() if np.count_nonzero(digitized == i) else np.NAN\n",
    "            for i in range(1, len(bins))\n",
    "        ]\n",
    "    )\n",
    "    bm = np.array(\n",
    "        [\n",
    "            power2D[digitized == i].mean()\n",
    "            if np.count_nonzero(digitized == i)\n",
    "            else np.NAN\n",
    "            for i in range(1, len(bins))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    bin_centers = bc[np.isfinite(bm)]\n",
    "    bin_means = bm[np.isfinite(bm)]\n",
    "\n",
    "    return np.column_stack((bin_centers, bin_means, bin_centers**4 * bin_means))\n",
    "\n",
    "\n",
    "def radial_averaging_series(power2D, mc, min_bin=0.001, max_bin=1, bin_width=0.001):\n",
    "    \"\"\"\n",
    "    Perform radial averaging over multiple frames in a time series. \n",
    "\n",
    "    Radially average the power spectrum to obtain values. Notably the natural freqeuncy unit\n",
    "    of this function is A^-1.\n",
    "\n",
    "    Args:\n",
    "        power2D (numpy.array((M,N,N))): Power spectrum\n",
    "        mc (_type_): Membrane curvature object with metadata\n",
    "        min_bin (float, optional): Minimum bin value. Defaults to 0.001.\n",
    "        max_bin (int, optional): Maximum bin value. Defaults to 1.\n",
    "        bin_width (float, optional): Bin width. Defaults to 0.001.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Binned power spectra\n",
    "    \"\"\"\n",
    "\n",
    "    if not len(power2D.shape) == 3:\n",
    "        raise RuntimeError(\"Expected time series of 2D power\")\n",
    "\n",
    "    x, y = np.meshgrid(mc[\"qx\"], mc[\"qy\"])  # A^-1\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    bins = np.arange(min_bin, max_bin, bin_width)\n",
    "\n",
    "    digitized = np.digitize(r, bins)\n",
    "    bc = np.array(\n",
    "        [\n",
    "            r[digitized == i].mean() if np.count_nonzero(digitized == i) else np.NAN\n",
    "            for i in range(1, len(bins))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    first_iter = True\n",
    "\n",
    "    spectra = None\n",
    "\n",
    "    for i, frame in tqdm(enumerate(power2D), total=len(power2D)):\n",
    "        bm = np.array(\n",
    "            [\n",
    "                frame[digitized == i].mean()\n",
    "                if np.count_nonzero(digitized == i)\n",
    "                else np.NAN\n",
    "                for i in range(1, len(bins))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if i == 0:\n",
    "            bin_centers = bc[np.isfinite(bm)]\n",
    "            bin_means = bm[np.isfinite(bm)]\n",
    "            spectra = np.zeros((power2D.shape[0], len(bin_means)))\n",
    "            spectra[i] = bin_means\n",
    "        else:\n",
    "            spectra[i] = bm[np.isfinite(bm)]\n",
    "    return (bin_centers, spectra)\n",
    "\n",
    "\n",
    "# def radial_averaging_nm(power2D, mc, min_bin=0.1, max_bin=10, bin_width=0.1):\n",
    "#     x, y = np.meshgrid(mc.qx * 10, mc.qy * 10)  # convert to nm^-1\n",
    "#     r = np.sqrt(x**2 + y**2)\n",
    "#     bins = np.arange(min_bin, max_bin, bin_width)\n",
    "\n",
    "#     digitized = np.digitize(r, bins)\n",
    "#     bc = np.array(\n",
    "#         [\n",
    "#             r[digitized == i].mean() if np.count_nonzero(digitized == i) else np.NAN\n",
    "#             for i in range(1, len(bins))\n",
    "#         ]\n",
    "#     )\n",
    "#     bm = np.array(\n",
    "#         [\n",
    "#             power2D[digitized == i].mean()\n",
    "#             if np.count_nonzero(digitized == i)\n",
    "#             else np.NAN\n",
    "#             for i in range(1, len(bins))\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     bin_centers = bc[np.isfinite(bm)]\n",
    "#     bin_means = bm[np.isfinite(bm)]\n",
    "\n",
    "#     return np.column_stack((bin_centers, bin_means, bin_centers**4 * bin_means))\n",
    "\n",
    "\n",
    "def count_residues(u):\n",
    "    count_dict = {}\n",
    "    for residue in u.residues:\n",
    "        if residue.resname not in count_dict:\n",
    "            count_dict[residue.resname] = 1\n",
    "        else:\n",
    "            count_dict[residue.resname] += 1\n",
    "    return count_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8363048-08a9-491b-ab9f-9cdf135bffbf",
   "metadata": {},
   "source": [
    "### Load data from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(util.analysis_path / \"mc_noobject.pickle\", \"rb\") as handle:\n",
    "    mc = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9fdb9-75f6-4c1a-8f58-6c099ac6df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_reload_all = False # Ignore cache and reload all data.\n",
    "\n",
    "mc = {}\n",
    "for sim in util.simulations:\n",
    "    if not force_reload_all:\n",
    "        if sim in mc:\n",
    "            continue\n",
    "    with open(util.analysis_path / f\"{sim}/membrane_curvature.pickle\", \"rb\") as handle:\n",
    "        mc[sim] = pickle.load(handle) \n",
    "\n",
    "## LOAD pickles in parallel. Seems to use a ton of memory...\n",
    "# def read_pickle(sim):\n",
    "#     with open(util.analysis_path / f\"{sim}/membrane_curvature.pickle\", \"rb\") as handle:\n",
    "#         mc[sim] = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38948c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24'])\n"
     ]
    }
   ],
   "source": [
    "print(mc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6910f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P <class 'numpy.ndarray'>\n",
      "Q <class 'numpy.ndarray'>\n",
      "ag <class 'dict'>\n",
      "frames <class 'numpy.ndarray'>\n",
      "interpolate <class 'bool'>\n",
      "n_frames <class 'int'>\n",
      "n_x_bins <class 'int'>\n",
      "n_y_bins <class 'int'>\n",
      "qx <class 'numpy.ndarray'>\n",
      "qy <class 'numpy.ndarray'>\n",
      "results <class 'MDAnalysis.analysis.base.Results'>\n",
      "run <class 'method'>\n",
      "start <class 'int'>\n",
      "step <class 'int'>\n",
      "stop <class 'int'>\n",
      "times <class 'numpy.ndarray'>\n",
      "wrap <class 'bool'>\n",
      "x_range <class 'tuple'>\n",
      "x_step <class 'float'>\n",
      "y_range <class 'tuple'>\n",
      "y_step <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Print out the items contained by the pickled curvature object\n",
    "for item in dir(mc[\"1\"]):\n",
    "    if not item.startswith(\"_\"):\n",
    "        print(item, type(getattr(mc[\"1\"],item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3498079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip out difficult to port objects from cache\n",
    "\n",
    "without_mdanalysis_objects = {}\n",
    "\n",
    "skip = [\"ag\", \"results\", \"run\"]\n",
    "\n",
    "for sim in util.simulations:\n",
    "    without_mdanalysis_objects[sim] = {}\n",
    "\n",
    "    for item in dir(mc[sim]):\n",
    "        if not item.startswith(\"_\") and item not in skip:\n",
    "            # print(item, type(getattr(mc[\"1\"],item)))\n",
    "            without_mdanalysis_objects[sim][item] = getattr(mc[sim],item)\n",
    "        elif item == \"results\":\n",
    "            for key in mc[sim].results.keys():\n",
    "                without_mdanalysis_objects[sim][key] = getattr(mc[sim],item)[key]\n",
    "\n",
    "with open(\"mc_noobject.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(without_mdanalysis_objects, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fd640-bb0d-4e99-aedc-57bef62e21ea",
   "metadata": {},
   "source": [
    "### System information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466d3571-37e6-4cb0-b63d-f51ab6ffac0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f48cae4a0e7443487a4b77fad0334d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System 1: DOPC: 0.46; DOPG: 0.00; POPE: 0.03; DOPE: 0.27; CDL1: 0.12; POPC: 0.12; CDL2POPG: 0.00; \n",
      "System 2: DOPC: 0.25; DOPG: 0.00; POPE: 0.08; DOPE: 0.29; CDL1: 0.12; POPC: 0.26; CDL2POPG: 0.00; \n",
      "System 3: DOPC: 0.22; DOPG: 0.00; POPE: 0.14; DOPE: 0.18; CDL1: 0.12; POPC: 0.34; CDL2POPG: 0.00; \n",
      "System 4: DOPC: 0.59; DOPG: 0.05; POPE: 0.02; DOPE: 0.23; CDL1: 0.00; POPC: 0.11; CDL2POPG: 0.00; \n",
      "System 5: DOPC: 0.39; DOPG: 0.02; POPE: 0.08; DOPE: 0.28; CDL1: 0.00; POPC: 0.23; CDL2POPG: 0.00; \n",
      "System 6: DOPC: 0.23; DOPG: 0.02; POPE: 0.16; DOPE: 0.20; CDL1: 0.00; POPC: 0.39; CDL2POPG: 0.00; \n",
      "System 7: DOPC: 0.00; DOPG: 0.00; POPE: 0.00; DOPE: 0.00; CDL1: 1.00; POPC: 0.00; CDL2POPG: 0.00; \n",
      "System 8: DOPC: 0.00; DOPG: 0.00; POPE: 0.30; DOPE: 0.00; CDL1: 0.20; POPC: 0.50; CDL2POPG: 0.00; \n",
      "System 9: DOPC: 0.50; DOPG: 0.00; POPE: 0.00; DOPE: 0.30; CDL1: 0.20; POPC: 0.00; CDL2POPG: 0.00; \n",
      "System 10: DOPC: 0.00; DOPG: 0.20; POPE: 0.30; DOPE: 0.00; CDL1: 0.00; POPC: 0.50; CDL2POPG: 0.00; \n",
      "System 11: DOPC: 0.50; DOPG: 0.20; POPE: 0.00; DOPE: 0.30; CDL1: 0.00; POPC: 0.00; CDL2POPG: 0.00; \n",
      "System 12: DOPC: 0.30; DOPG: 0.02; POPE: 0.25; DOPE: 0.24; CDL1: 0.00; POPC: 0.19; CDL2POPG: 0.00; \n",
      "System 13: DOPC: 0.44; DOPG: 0.00; POPE: 0.03; DOPE: 0.26; CDL1: 0.16; POPC: 0.11; CDL2POPG: 0.00; \n",
      "System 14: DOPC: 0.48; DOPG: 0.00; POPE: 0.03; DOPE: 0.28; CDL1: 0.09; POPC: 0.12; CDL2POPG: 0.00; \n",
      "System 15: DOPC: 0.26; DOPG: 0.00; POPE: 0.22; DOPE: 0.22; CDL1: 0.12; POPC: 0.18; CDL2POPG: 0.00; \n",
      "System 16: DOPC: 0.52; DOPG: 0.00; POPE: 0.03; DOPE: 0.31; CDL1: 0.00; POPC: 0.14; CDL2POPG: 0.00; \n",
      "System 17: DOPC: 0.28; DOPG: 0.00; POPE: 0.09; DOPE: 0.33; CDL1: 0.00; POPC: 0.30; CDL2POPG: 0.00; \n",
      "System 18: DOPC: 0.25; DOPG: 0.00; POPE: 0.16; DOPE: 0.20; CDL1: 0.00; POPC: 0.39; CDL2POPG: 0.00; \n",
      "System 19: DOPC: 0.00; DOPG: 0.00; POPE: 0.00; DOPE: 0.00; CDL1: 0.00; POPC: 0.00; CDL2POPG: 0.00; \n",
      "System 20: DOPC: 0.00; DOPG: 0.00; POPE: 0.37; DOPE: 0.00; CDL1: 0.00; POPC: 0.63; CDL2POPG: 0.00; \n",
      "System 21: DOPC: 0.63; DOPG: 0.00; POPE: 0.00; DOPE: 0.37; CDL1: 0.00; POPC: 0.00; CDL2POPG: 0.00; \n",
      "System 22: DOPC: 0.52; DOPG: 0.00; POPE: 0.04; DOPE: 0.31; CDL1: 0.00; POPC: 0.13; CDL2POPG: 0.00; \n",
      "System 23: DOPC: 0.53; DOPG: 0.00; POPE: 0.03; DOPE: 0.31; CDL1: 0.00; POPC: 0.13; CDL2POPG: 0.00; \n",
      "System 24: DOPC: 0.30; DOPG: 0.00; POPE: 0.25; DOPE: 0.25; CDL1: 0.00; POPC: 0.20; CDL2POPG: 0.00; \n"
     ]
    }
   ],
   "source": [
    "def get_compositions(sim):\n",
    "    top = util.analysis_path / sim / \"system.top\"\n",
    "    gro = util.analysis_path / sim / \"membrane_only.gro\"\n",
    "\n",
    "    u = MDAnalysis.Universe(top, gro, topology_format=\"ITP\")\n",
    "    raw_composition = count_residues(u)\n",
    "\n",
    "    total_lipids = 0\n",
    "    for lipid in util.lipid_names:\n",
    "        if lipid in raw_composition:\n",
    "            total_lipids += raw_composition[lipid]\n",
    "\n",
    "    normed_composition = {}\n",
    "    s = \"\"\n",
    "    for lipid in util.lipid_names:\n",
    "        if lipid in raw_composition:\n",
    "            s += f\"{lipid}: {raw_composition[lipid]/total_lipids:0.2f}; \"\n",
    "            normed_composition[lipid] = raw_composition[lipid] / total_lipids\n",
    "        else:\n",
    "            s += f\"{lipid}: {0:0.2f}; \"\n",
    "            normed_composition[lipid] = 0\n",
    "    print(sim, total_lipids)    \n",
    "    return sim, raw_composition, normed_composition, s\n",
    "\n",
    "\n",
    "result = map(get_compositions, util.simulations)\n",
    "\n",
    "compositions = {}\n",
    "for sim, raw, normed, s in result:\n",
    "    print(f\"System {sim}: {s}\")\n",
    "    compositions[sim, \"raw_composition\"] = raw\n",
    "    compositions[sim, \"normed_composition\"] = normed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f4f313",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The topology and GRO trajectory files don't have the same number of atoms!\nTopology number of atoms 74544\nTrajectory: /Users/ctlee/Downloads/mito_lipidomics/analysis/3/production5.gro Number of atoms 340213",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(get_compositions(\u001b[39m\"\u001b[39;49m\u001b[39m3\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn [6], line 5\u001b[0m, in \u001b[0;36mget_compositions\u001b[0;34m(sim)\u001b[0m\n\u001b[1;32m      2\u001b[0m top \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39manalysis_path \u001b[39m/\u001b[39m sim \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msystem.top\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m gro \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39manalysis_path \u001b[39m/\u001b[39m sim \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mproduction5.gro\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m u \u001b[39m=\u001b[39m MDAnalysis\u001b[39m.\u001b[39;49mUniverse(top, gro, topology_format\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mITP\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m raw_composition \u001b[39m=\u001b[39m count_residues(u)\n\u001b[1;32m      8\u001b[0m total_lipids \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:365\u001b[0m, in \u001b[0;36mUniverse.__init__\u001b[0;34m(self, topology, all_coordinates, format, topology_format, transformations, guess_bonds, vdwradii, in_memory, in_memory_step, *coordinates, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m coordinates \u001b[39m=\u001b[39m _resolve_coordinates(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename, \u001b[39m*\u001b[39mcoordinates,\n\u001b[1;32m    361\u001b[0m                                    \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m,\n\u001b[1;32m    362\u001b[0m                                    all_coordinates\u001b[39m=\u001b[39mall_coordinates)\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m coordinates:\n\u001b[0;32m--> 365\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_new(coordinates, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m, in_memory\u001b[39m=\u001b[39;49min_memory,\n\u001b[1;32m    366\u001b[0m                 in_memory_step\u001b[39m=\u001b[39;49min_memory_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    368\u001b[0m \u001b[39mif\u001b[39;00m transformations:\n\u001b[1;32m    369\u001b[0m     \u001b[39mif\u001b[39;00m callable(transformations):\n",
      "File \u001b[0;32m~/mambaforge/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:569\u001b[0m, in \u001b[0;36mUniverse.load_new\u001b[0;34m(self, filename, format, in_memory, in_memory_step, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory \u001b[39m=\u001b[39m reader(filename, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory\u001b[39m.\u001b[39mn_atoms \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39matoms):\n\u001b[0;32m--> 569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe topology and \u001b[39m\u001b[39m{form}\u001b[39;00m\u001b[39m trajectory files don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m have the same number of atoms!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mTopology number of atoms \u001b[39m\u001b[39m{top_n_atoms}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mTrajectory: \u001b[39m\u001b[39m{fname}\u001b[39;00m\u001b[39m Number of atoms \u001b[39m\u001b[39m{trj_n_atoms}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    573\u001b[0m                          form\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory\u001b[39m.\u001b[39mformat,\n\u001b[1;32m    574\u001b[0m                          top_n_atoms\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39matoms),\n\u001b[1;32m    575\u001b[0m                          fname\u001b[39m=\u001b[39mfilename,\n\u001b[1;32m    576\u001b[0m                          trj_n_atoms\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory\u001b[39m.\u001b[39mn_atoms))\n\u001b[1;32m    578\u001b[0m \u001b[39mif\u001b[39;00m in_memory:\n\u001b[1;32m    579\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransfer_to_memory(step\u001b[39m=\u001b[39min_memory_step, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: The topology and GRO trajectory files don't have the same number of atoms!\nTopology number of atoms 74544\nTrajectory: /Users/ctlee/Downloads/mito_lipidomics/analysis/3/production5.gro Number of atoms 340213"
     ]
    }
   ],
   "source": [
    "print(get_compositions(\"3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed2ec8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(compositions[sim, \u001b[39m\"\u001b[39m\u001b[39mraw_composition\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sim' is not defined"
     ]
    }
   ],
   "source": [
    "print(compositions[sim, \"raw_composition\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80a6f0",
   "metadata": {},
   "source": [
    "## Defining Statistical Inefficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76677f3f",
   "metadata": {},
   "source": [
    "Given a sequence of measurements $A_i$ sampled from a timeseries, we must investigate the degree of correlation to estimate the sampling error. We estimate the error by quantifying the statistical inefficiency.\n",
    "\n",
    "We start by computing the block averaged values, $\\langle A\\rangle_b$ over a range of block lengths $t_b$,\n",
    "$$\\langle A\\rangle_b = \\frac{1}{t_b} \\sum_{i=1}^{t_b} A_i.$$\n",
    "\n",
    "As the number of steps increases, we expect that the block averages become uncorrelated. The variance of block averages $\\sigma^2(\\langle A\\rangle_b)$,\n",
    "$$\\sigma^2(\\langle A\\rangle_b) = \\frac{1}{n_b}\\sum_{b=1}^{n_b} (\\langle A\\rangle_b - \\langle A_i\\rangle)^2,$$\n",
    "becomes inversely proportional to $t_b$ as the block averages become uncorrelated.\n",
    "\n",
    "At the uncorrelated limit, the statistical inefficiency is given by,\n",
    "$$ s = \\lim_{t_b\\rightarrow \\infty} \\frac{t_b \\sigma^2(\\langle A\\rangle_b)}{\\sigma^2(A)}.$$\n",
    "\n",
    "The 'true' standard deviation of the average value is then related to the traditional standard deviation by,\n",
    "$$\\sigma_{\\langle A\\rangle} \\approx \\sigma \\sqrt{\\frac{s}{M}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c8c72",
   "metadata": {},
   "source": [
    "## Setting up parametric error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc5c57",
   "metadata": {},
   "source": [
    "Given a sequence of evenly space measurements ${X_1, X_2,\\ldots, X_T}$ along a trajectory, the sample mean $m_X$ and sample variance $s^2_X$ is given by\n",
    "\n",
    "$$m_X = \\frac{1}{T} \\sum_{i=1}^{T}X_i,$$\n",
    "$$s^2_X = \\frac{1}{T-1}\\sum_{i=1}^{T}(X_i - m_X)^2.$$\n",
    "\n",
    "The error of the mean can be estimated using $\\delta X = s_X / \\sqrt{T}$ if the data are uncorrelated. Since the measurements are sampled from a dynamical trajectory, there is no guarantee that there is no correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efb48a-b085-46e4-9f1d-9b76c46cdbc4",
   "metadata": {},
   "source": [
    "## Kc Bending Modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab73780",
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_low_q = 0.4 / 10  # A^-1\n",
    "\n",
    "def fit_kc_from_power(\n",
    "    power2D, mc=None, threshold=0.03, min_bin=0.001, max_bin=1, bin_width=0.001\n",
    "):\n",
    "    spectra = radial_averaging(\n",
    "        power2D, mc, min_bin=min_bin, max_bin=max_bin, bin_width=bin_width\n",
    "    )\n",
    "    mask = spectra[:, 0] < threshold\n",
    "    spectra_cut = spectra[mask, :]\n",
    "\n",
    "    return 1.0 / spectra_cut[:, 2].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8eb54f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ctlee/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/topology/guessers.py:146: UserWarning: Failed to guess the mass for the following atom types: G\n",
      "  warnings.warn(\"Failed to guess the mass for the following atom types: {}\".format(atom_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: mean 436.6358947753906, min 430.8668212890625, max 440.47406005859375 Angstroms\n",
      "2: mean 434.1571350097656, min 429.5400390625, max 437.6881103515625 Angstroms\n",
      "3: mean 433.9451904296875, min 426.68695068359375, max 437.3980712890625 Angstroms\n",
      "4: mean 420.0805969238281, min 416.2216796875, max 422.55755615234375 Angstroms\n",
      "5: mean 416.7505798339844, min 412.7535705566406, max 419.20233154296875 Angstroms\n",
      "6: mean 390.9449768066406, min 390.7454833984375, max 391.19720458984375 Angstroms\n",
      "7: mean 568.2291870117188, min 557.763427734375, max 573.7001342773438 Angstroms\n",
      "8: mean 442.5380859375, min 437.019287109375, max 446.69976806640625 Angstroms\n",
      "9: mean 448.32891845703125, min 440.024169921875, max 453.9234924316406 Angstroms\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/u2/ctlee/mito_lipidomics_scratch/analysis/10/po4_only.gro'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m traj \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39manalysis_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msim\u001b[39m}\u001b[39;00m\u001b[39m/po4_all.xtc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m u \u001b[39m=\u001b[39m MDAnalysis\u001b[39m.\u001b[39;49mUniverse(gro, \u001b[39mstr\u001b[39;49m(traj), refresh_offsets\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m dims \u001b[39m=\u001b[39m [u\u001b[39m.\u001b[39mdimensions[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m ts \u001b[39min\u001b[39;00m u\u001b[39m.\u001b[39mtrajectory]\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:346\u001b[0m, in \u001b[0;36mUniverse.__init__\u001b[0;34m(self, topology, all_coordinates, format, topology_format, transformations, guess_bonds, vdwradii, in_memory, in_memory_step, *coordinates, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m _check_file_like(topology)\n\u001b[0;32m--> 346\u001b[0m     topology \u001b[39m=\u001b[39m _topology_from_file_like(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename,\n\u001b[1;32m    347\u001b[0m                                         topology_format\u001b[39m=\u001b[39;49mtopology_format,\n\u001b[1;32m    348\u001b[0m                                         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    350\u001b[0m \u001b[39mif\u001b[39;00m topology \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:118\u001b[0m, in \u001b[0;36m_topology_from_file_like\u001b[0;34m(topology_file, topology_format, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m (err\u001b[39m.\u001b[39merrno \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     errno\u001b[39m.\u001b[39merrorcode[err\u001b[39m.\u001b[39merrno] \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mENOENT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEACCES\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    117\u001b[0m     \u001b[39m# Runs if the error is propagated due to no permission / file not found\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mraise\u001b[39;00m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m] \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[39m# Runs when the parser fails\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:110\u001b[0m, in \u001b[0;36m_topology_from_file_like\u001b[0;34m(topology_file, topology_format, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[39mwith\u001b[39;00m parser(topology_file) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m--> 110\u001b[0m         topology \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mparse(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    111\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# There are 2 kinds of errors that might be raised here:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39m# one because the file isn't present\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39m# or the permissions are bad, second when the parser fails\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/topology/GROParser.py:84\u001b[0m, in \u001b[0;36mGROParser.parse\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m# Gro has the following columns\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m# resid, resname, name, index, (x,y,z)\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[39mwith\u001b[39;00m openany(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename) \u001b[39mas\u001b[39;00m inf:\n\u001b[1;32m     85\u001b[0m     \u001b[39mnext\u001b[39m(inf)\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:316\u001b[0m, in \u001b[0;36mopenany\u001b[0;34m(datasource, mode, reset)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39m\"\"\"Context manager for :func:`anyopen`.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[39mOpen the `datasource` and close it when the context of the :keyword:`with`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m:func:`anyopen`\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m stream \u001b[39m=\u001b[39m anyopen(datasource, mode\u001b[39m=\u001b[39;49mmode, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:395\u001b[0m, in \u001b[0;36manyopen\u001b[0;34m(datasource, mode, reset)\u001b[0m\n\u001b[1;32m    394\u001b[0m openfunc \u001b[39m=\u001b[39m read_handlers[ext]\n\u001b[0;32m--> 395\u001b[0m stream \u001b[39m=\u001b[39m _get_stream(datasource, openfunc, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m stream \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:437\u001b[0m, in \u001b[0;36m_get_stream\u001b[0;34m(filename, openfunction, mode)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mif\u001b[39;00m errno\u001b[39m.\u001b[39merrorcode[err\u001b[39m.\u001b[39merrno] \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mENOENT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEACCES\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m--> 437\u001b[0m     \u001b[39mraise\u001b[39;00m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m] \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:431\u001b[0m, in \u001b[0;36m_get_stream\u001b[0;34m(filename, openfunction, mode)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     stream \u001b[39m=\u001b[39m openfunction(filename, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    433\u001b[0m     \u001b[39m# An exception might be raised due to two reasons, first the openfunction is unable to open the file, in this\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39m# case we have to ignore the error and return None. Second is when openfunction can't open the file because\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     \u001b[39m# either the file isn't there or the permissions don't allow access.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/picklable_file_io.py:478\u001b[0m, in \u001b[0;36mbz2_pickle_open\u001b[0;34m(name, mode)\u001b[0m\n\u001b[1;32m    477\u001b[0m bz_mode \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 478\u001b[0m binary_file \u001b[39m=\u001b[39m BZ2Picklable(name, bz_mode)\n\u001b[1;32m    479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/picklable_file_io.py:266\u001b[0m, in \u001b[0;36mBZ2Picklable.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bz_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m--> 266\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name, mode)\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/bz2.py:81\u001b[0m, in \u001b[0;36mBZ2File.__init__\u001b[0;34m(self, filename, mode, compresslevel)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filename, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m, os\u001b[39m.\u001b[39mPathLike)):\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp \u001b[39m=\u001b[39m _builtin_open(filename, mode)\n\u001b[1;32m     82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_closefp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/u2/ctlee/mito_lipidomics_scratch/analysis/10/po4_only.gro'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m traj \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39manalysis_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msim\u001b[39m}\u001b[39;00m\u001b[39m/po4_all.xtc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m u \u001b[39m=\u001b[39m MDAnalysis\u001b[39m.\u001b[39;49mUniverse(gro, \u001b[39mstr\u001b[39;49m(traj), refresh_offsets\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m dims \u001b[39m=\u001b[39m [u\u001b[39m.\u001b[39mdimensions[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m ts \u001b[39min\u001b[39;00m u\u001b[39m.\u001b[39mtrajectory]\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:346\u001b[0m, in \u001b[0;36mUniverse.__init__\u001b[0;34m(self, topology, all_coordinates, format, topology_format, transformations, guess_bonds, vdwradii, in_memory, in_memory_step, *coordinates, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m _check_file_like(topology)\n\u001b[0;32m--> 346\u001b[0m     topology \u001b[39m=\u001b[39m _topology_from_file_like(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename,\n\u001b[1;32m    347\u001b[0m                                         topology_format\u001b[39m=\u001b[39;49mtopology_format,\n\u001b[1;32m    348\u001b[0m                                         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    350\u001b[0m \u001b[39mif\u001b[39;00m topology \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:118\u001b[0m, in \u001b[0;36m_topology_from_file_like\u001b[0;34m(topology_file, topology_format, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m (err\u001b[39m.\u001b[39merrno \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     errno\u001b[39m.\u001b[39merrorcode[err\u001b[39m.\u001b[39merrno] \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mENOENT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEACCES\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    117\u001b[0m     \u001b[39m# Runs if the error is propagated due to no permission / file not found\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mraise\u001b[39;00m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m] \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[39m# Runs when the parser fails\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:110\u001b[0m, in \u001b[0;36m_topology_from_file_like\u001b[0;34m(topology_file, topology_format, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[39mwith\u001b[39;00m parser(topology_file) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m--> 110\u001b[0m         topology \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mparse(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    111\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# There are 2 kinds of errors that might be raised here:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39m# one because the file isn't present\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39m# or the permissions are bad, second when the parser fails\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/topology/GROParser.py:84\u001b[0m, in \u001b[0;36mGROParser.parse\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m# Gro has the following columns\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m# resid, resname, name, index, (x,y,z)\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[39mwith\u001b[39;00m openany(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename) \u001b[39mas\u001b[39;00m inf:\n\u001b[1;32m     85\u001b[0m     \u001b[39mnext\u001b[39m(inf)\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:316\u001b[0m, in \u001b[0;36mopenany\u001b[0;34m(datasource, mode, reset)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39m\"\"\"Context manager for :func:`anyopen`.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[39mOpen the `datasource` and close it when the context of the :keyword:`with`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m:func:`anyopen`\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m stream \u001b[39m=\u001b[39m anyopen(datasource, mode\u001b[39m=\u001b[39;49mmode, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:395\u001b[0m, in \u001b[0;36manyopen\u001b[0;34m(datasource, mode, reset)\u001b[0m\n\u001b[1;32m    394\u001b[0m openfunc \u001b[39m=\u001b[39m read_handlers[ext]\n\u001b[0;32m--> 395\u001b[0m stream \u001b[39m=\u001b[39m _get_stream(datasource, openfunc, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m stream \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:437\u001b[0m, in \u001b[0;36m_get_stream\u001b[0;34m(filename, openfunction, mode)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mif\u001b[39;00m errno\u001b[39m.\u001b[39merrorcode[err\u001b[39m.\u001b[39merrno] \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mENOENT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEACCES\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m--> 437\u001b[0m     \u001b[39mraise\u001b[39;00m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m] \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:431\u001b[0m, in \u001b[0;36m_get_stream\u001b[0;34m(filename, openfunction, mode)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     stream \u001b[39m=\u001b[39m openfunction(filename, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    433\u001b[0m     \u001b[39m# An exception might be raised due to two reasons, first the openfunction is unable to open the file, in this\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39m# case we have to ignore the error and return None. Second is when openfunction can't open the file because\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     \u001b[39m# either the file isn't there or the permissions don't allow access.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/picklable_file_io.py:478\u001b[0m, in \u001b[0;36mbz2_pickle_open\u001b[0;34m(name, mode)\u001b[0m\n\u001b[1;32m    477\u001b[0m bz_mode \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 478\u001b[0m binary_file \u001b[39m=\u001b[39m BZ2Picklable(name, bz_mode)\n\u001b[1;32m    479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/picklable_file_io.py:266\u001b[0m, in \u001b[0;36mBZ2Picklable.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bz_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m--> 266\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name, mode)\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/bz2.py:81\u001b[0m, in \u001b[0;36mBZ2File.__init__\u001b[0;34m(self, filename, mode, compresslevel)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filename, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m, os\u001b[39m.\u001b[39mPathLike)):\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp \u001b[39m=\u001b[39m _builtin_open(filename, mode)\n\u001b[1;32m     82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_closefp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/u2/ctlee/mito_lipidomics_scratch/analysis/10/po4_only.gro'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m gro \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39manalysis_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msim\u001b[39m}\u001b[39;00m\u001b[39m/po4_only.gro\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m traj \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39manalysis_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msim\u001b[39m}\u001b[39;00m\u001b[39m/po4_all.xtc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m u \u001b[39m=\u001b[39m MDAnalysis\u001b[39m.\u001b[39;49mUniverse(gro, \u001b[39mstr\u001b[39;49m(traj), refresh_offsets\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m dims \u001b[39m=\u001b[39m [u\u001b[39m.\u001b[39mdimensions[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m ts \u001b[39min\u001b[39;00m u\u001b[39m.\u001b[39mtrajectory]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcortex/home/ctlee/2022-mitochondria-lipidomics-md/scripts/mito_lipidomics.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msim\u001b[39m}\u001b[39;00m\u001b[39m: mean \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(dims)\u001b[39m}\u001b[39;00m\u001b[39m, min \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmin(dims)\u001b[39m}\u001b[39;00m\u001b[39m, max \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmax(dims)\u001b[39m}\u001b[39;00m\u001b[39m Angstroms\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:346\u001b[0m, in \u001b[0;36mUniverse.__init__\u001b[0;34m(self, topology, all_coordinates, format, topology_format, transformations, guess_bonds, vdwradii, in_memory, in_memory_step, *coordinates, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(topology, Topology) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m topology \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m _check_file_like(topology)\n\u001b[0;32m--> 346\u001b[0m     topology \u001b[39m=\u001b[39m _topology_from_file_like(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename,\n\u001b[1;32m    347\u001b[0m                                         topology_format\u001b[39m=\u001b[39;49mtopology_format,\n\u001b[1;32m    348\u001b[0m                                         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    350\u001b[0m \u001b[39mif\u001b[39;00m topology \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_topology \u001b[39m=\u001b[39m topology\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:118\u001b[0m, in \u001b[0;36m_topology_from_file_like\u001b[0;34m(topology_file, topology_format, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# There are 2 kinds of errors that might be raised here:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39m# one because the file isn't present\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39m# or the permissions are bad, second when the parser fails\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m (err\u001b[39m.\u001b[39merrno \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         errno\u001b[39m.\u001b[39merrorcode[err\u001b[39m.\u001b[39merrno] \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mENOENT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEACCES\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    117\u001b[0m         \u001b[39m# Runs if the error is propagated due to no permission / file not found\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m         \u001b[39mraise\u001b[39;00m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m] \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[39m# Runs when the parser fails\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFailed to load from the topology file \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39m with parser \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mError: \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(topology_file, parser, err))\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:110\u001b[0m, in \u001b[0;36m_topology_from_file_like\u001b[0;34m(topology_file, topology_format, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[39mwith\u001b[39;00m parser(topology_file) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m--> 110\u001b[0m         topology \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mparse(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    111\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# There are 2 kinds of errors that might be raised here:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39m# one because the file isn't present\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39m# or the permissions are bad, second when the parser fails\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m (err\u001b[39m.\u001b[39merrno \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         errno\u001b[39m.\u001b[39merrorcode[err\u001b[39m.\u001b[39merrno] \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mENOENT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEACCES\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    117\u001b[0m         \u001b[39m# Runs if the error is propagated due to no permission / file not found\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/topology/GROParser.py:84\u001b[0m, in \u001b[0;36mGROParser.parse\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39m\"\"\"Return the *Topology* object for this file\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39m# Gro has the following columns\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m# resid, resname, name, index, (x,y,z)\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[39mwith\u001b[39;00m openany(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename) \u001b[39mas\u001b[39;00m inf:\n\u001b[1;32m     85\u001b[0m     \u001b[39mnext\u001b[39m(inf)\n\u001b[1;32m     86\u001b[0m     n_atoms \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mnext\u001b[39m(inf))\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:316\u001b[0m, in \u001b[0;36mopenany\u001b[0;34m(datasource, mode, reset)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39m@contextmanager\u001b[39m\n\u001b[1;32m    273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopenany\u001b[39m(datasource, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrt\u001b[39m\u001b[39m'\u001b[39m, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    274\u001b[0m     \u001b[39m\"\"\"Context manager for :func:`anyopen`.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[39m    Open the `datasource` and close it when the context of the :keyword:`with`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m    :func:`anyopen`\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     stream \u001b[39m=\u001b[39m anyopen(datasource, mode\u001b[39m=\u001b[39;49mmode, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    317\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         \u001b[39myield\u001b[39;00m stream\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:395\u001b[0m, in \u001b[0;36manyopen\u001b[0;34m(datasource, mode, reset)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39mfor\u001b[39;00m ext \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mbz2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# file == '' should be last\u001b[39;00m\n\u001b[1;32m    394\u001b[0m     openfunc \u001b[39m=\u001b[39m read_handlers[ext]\n\u001b[0;32m--> 395\u001b[0m     stream \u001b[39m=\u001b[39m _get_stream(datasource, openfunc, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m stream \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:437\u001b[0m, in \u001b[0;36m_get_stream\u001b[0;34m(filename, openfunction, mode)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    433\u001b[0m     \u001b[39m# An exception might be raised due to two reasons, first the openfunction is unable to open the file, in this\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39m# case we have to ignore the error and return None. Second is when openfunction can't open the file because\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     \u001b[39m# either the file isn't there or the permissions don't allow access.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m errno\u001b[39m.\u001b[39merrorcode[err\u001b[39m.\u001b[39merrno] \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mENOENT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEACCES\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m--> 437\u001b[0m         \u001b[39mraise\u001b[39;00m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m] \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m mode\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    440\u001b[0m     \u001b[39m# additional check for reading (eg can we uncompress) --- is this needed?\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/util.py:431\u001b[0m, in \u001b[0;36m_get_stream\u001b[0;34m(filename, openfunction, mode)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m\"\"\"Return open stream if *filename* can be opened with *openfunction* or else ``None``.\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     stream \u001b[39m=\u001b[39m openfunction(filename, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    433\u001b[0m     \u001b[39m# An exception might be raised due to two reasons, first the openfunction is unable to open the file, in this\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39m# case we have to ignore the error and return None. Second is when openfunction can't open the file because\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     \u001b[39m# either the file isn't there or the permissions don't allow access.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m errno\u001b[39m.\u001b[39merrorcode[err\u001b[39m.\u001b[39merrno] \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mENOENT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEACCES\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/picklable_file_io.py:478\u001b[0m, in \u001b[0;36mbz2_pickle_open\u001b[0;34m(name, mode)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly read mode (\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrt\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    476\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mfiles can be pickled.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    477\u001b[0m bz_mode \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 478\u001b[0m binary_file \u001b[39m=\u001b[39m BZ2Picklable(name, bz_mode)\n\u001b[1;32m    479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    480\u001b[0m     \u001b[39mreturn\u001b[39;00m TextIOPicklable(binary_file)\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/site-packages/MDAnalysis/lib/picklable_file_io.py:266\u001b[0m, in \u001b[0;36mBZ2Picklable.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bz_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m--> 266\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name, mode)\n",
      "File \u001b[0;32m~/.conda/envs/mda/lib/python3.10/bz2.py:81\u001b[0m, in \u001b[0;36mBZ2File.__init__\u001b[0;34m(self, filename, mode, compresslevel)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid mode: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (mode,))\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filename, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m, os\u001b[39m.\u001b[39mPathLike)):\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp \u001b[39m=\u001b[39m _builtin_open(filename, mode)\n\u001b[1;32m     82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_closefp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m mode_code\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/u2/ctlee/mito_lipidomics_scratch/analysis/10/po4_only.gro'"
     ]
    }
   ],
   "source": [
    "areas = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    gro = util.analysis_path / f\"{sim}/po4_only.gro\"\n",
    "    traj = util.analysis_path / f\"{sim}/po4_all.xtc\"\n",
    "\n",
    "    u = MDAnalysis.Universe(gro, str(traj), refresh_offsets=True)\n",
    "    dims = [u.dimensions[0] for ts in u.trajectory]\n",
    "    print(\n",
    "        f\"{sim}: mean {np.mean(dims)}, min {np.min(dims)}, max {np.max(dims)} Angstroms\"\n",
    "    )\n",
    "    areas[sim] = np.mean(dims) ** 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0434011",
   "metadata": {},
   "source": [
    "### Block analysis of Fourier modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e33a698d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f031cb0e0224d709e7c63848af77051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Override and recompute even if spectra pickle exists\n",
    "spectra_compute_override = False\n",
    "\n",
    "spectra_fd = util.analysis_path / \"spectra.pickle\"\n",
    "if spectra_fd.exists() and not spectra_compute_override:\n",
    "    # LOAD SPECTRA PICKLE\n",
    "    with open(spectra_fd, \"rb\") as handle:\n",
    "        spectra = pickle.load(handle)\n",
    "    print(\"Loaded spectra from cache!\")\n",
    "else:\n",
    "    def compute_spectra(sim):\n",
    "        return sim, radial_averaging_series(\n",
    "            mc[sim][\"height_power_spectrum\"],\n",
    "            mc[sim],\n",
    "            min_bin=0.001,\n",
    "            max_bin=1,\n",
    "            bin_width=0.001,\n",
    "        )\n",
    "\n",
    "    spectra = dict(map(compute_spectra, util.simulations))\n",
    "\n",
    "    # WRITE SPECTRA TO PICKLE\n",
    "    with open(spectra_fd, \"wb\") as handle:\n",
    "        pickle.dump(spectra, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# POPULATE q^4*h_q\n",
    "qfour_spectra = {}\n",
    "for sim in util.simulations:\n",
    "    qfour_spectra[sim] = np.power(spectra[sim][0], 4) * spectra[sim][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12798a11",
   "metadata": {},
   "source": [
    "#### Timeseries of wavenumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = False\n",
    "curr_fig_path = Path(\"Figures/power_timeseries\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "## PLOT HEIGHT POWER TIMESERIES\n",
    "for sim in util.simulations:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "\n",
    "    for i in range(0, 4):\n",
    "        ax.plot(\n",
    "            range(len(spectra[sim][1][:, i])),\n",
    "            spectra[sim][1][:, i],\n",
    "            linewidth=NORMAL_LINE,\n",
    "            label=f\"q{i}\",\n",
    "        )\n",
    "        \n",
    "        # plot q^4*h_q instead\n",
    "        # ax.plot(\n",
    "        #     range(len(spectra[sim][1][:, i])),\n",
    "        #     np.power(spectra[sim][0][i],4)*spectra[sim][1][:, i],\n",
    "        #     linewidth=NORMAL_LINE,\n",
    "        #     label=f\"q{i}\",\n",
    "        # )\n",
    "\n",
    "    ax.set_xlabel(r\"Frame\")\n",
    "    ax.set_ylabel(r\"Power Spectrum $\\langle|h_q|\\rangle^2$ (nm$^{-4}$)\")\n",
    "    ax.set_title(f\"Sys{sim}:{util.system_names[sim]}\")\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "    # # Shrink current axis by 20%\n",
    "    # box = ax.get_position()\n",
    "    # ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # # Put a legend to the right of the current axis\n",
    "    # ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(curr_fig_path/f\"{sim}_power_timeseries.png\", format=\"png\")\n",
    "\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "        \n",
    "    fig.clear()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f5e23",
   "metadata": {},
   "source": [
    "#### Statistical inefficiency of Fourier amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd271d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = False\n",
    "curr_fig_path = Path(\"Figures/amplitude_si\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "## COMPUTE STATISTICAL INEFFICIENCY OF WAVE NUMBERS UP TO max_q\n",
    "max_q = 4\n",
    "discards = np.arange(0, 60, 10)\n",
    "blocks = np.arange(1, 2**8 + 1, 1)\n",
    "\n",
    "cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "\n",
    "for sim in util.simulations:\n",
    "    for q in range(0, max_q):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "        c = cmap(np.linspace(0, 1, len(discards)))\n",
    "\n",
    "        _, _, si = util.statistical_inefficiency(\n",
    "            qfour_spectra[sim][:, q], blocks, discards\n",
    "        )\n",
    "\n",
    "        for d, discard in enumerate(discards):\n",
    "            ax.plot(\n",
    "                blocks,\n",
    "                si[d],\n",
    "                color=c[d],\n",
    "                linewidth=NORMAL_LINE,\n",
    "                label=f\"{100-discard}%\",\n",
    "            )\n",
    "\n",
    "        ax.set_xlabel(r\"Blocks\")\n",
    "        ax.set_ylabel(r\"Statistical inefficiency\")\n",
    "        ax.set_title(f\"Sys {sim}: {util.system_names[sim]}, q4Hq{q}\")\n",
    "        ax.legend(loc=\"upper left\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # # Shrink current axis by 20%\n",
    "        # box = ax.get_position()\n",
    "        # ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "        # # Put a legend to the right of the current axis\n",
    "        # ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        fig.savefig(curr_fig_path/f\"{sim}_q4Hq{q}.png\", format=\"png\")\n",
    "\n",
    "        if show_figs:\n",
    "            plt.show()\n",
    "        fig.clear()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c5122",
   "metadata": {},
   "source": [
    "Conclude that the wavenumbers appear to equilibrate rapidly and we can keep the majority of the trajectory. Henceforth we will discard 10% from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d23fbf",
   "metadata": {},
   "source": [
    "#### Block averaging of amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b76b6",
   "metadata": {},
   "source": [
    "The correlation time of the squared standard error of the mean should follow such a trend:\n",
    "$$\\frac{\\delta X^2_b}{\\delta X^2_1} = \\frac{1+c_t}{1-c_t} - \\frac{2*c_t}{b} * \\frac{1-c^b_t}{(1-c_t)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe38e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_time_sqrt(b, tau):\n",
    "    ct = np.exp(-1 / tau)\n",
    "    cb = np.exp(-b / tau)\n",
    "    return np.sqrt((1 + ct) / (1 - ct) - (2 * ct) / b * (1 - cb) / np.power(1 - ct, 2))\n",
    "\n",
    "def correlation_time(b, tau):\n",
    "    ct = np.exp(-1 / tau)\n",
    "    cb = np.exp(-b / tau)\n",
    "    return (1 + ct) / (1 - ct) - (2 * ct) / b * (1 - cb) / np.power(1 - ct, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard first X% for all trajectories\n",
    "discard = 10\n",
    "max_q_dict = {}\n",
    "blocks = np.arange(1, 2**9 + 1, 1)\n",
    "\n",
    "block_var = {}\n",
    "lp_block_sem = {}\n",
    "block_mean = {}\n",
    "for sim in util.simulations:\n",
    "    max_q = sum(spectra[sim][0] < kc_low_q)\n",
    "\n",
    "    max_q_dict[sim]  = max_q\n",
    "\n",
    "    block_mean[sim] = np.zeros((max_q, len(blocks)))\n",
    "    block_var[sim] = np.zeros((max_q, len(blocks)))\n",
    "    lp_block_sem[sim] = np.zeros((max_q, len(blocks)))\n",
    "\n",
    "    low_q_data = qfour_spectra[sim][:, 0:max_q]\n",
    "    # low_q_data = spectra[sim][1][:, 0:max_q]\n",
    "    \n",
    "    _, remainder = np.split(low_q_data, [int(discard / 100 * len(low_q_data))])\n",
    "\n",
    "    block_mean[sim] = util.nd_block_average(remainder, axis=0, func=np.mean, blocks=blocks)\n",
    "    block_var[sim] = util.nd_block_average(remainder, axis=0, func=partial(np.var, ddof=1), blocks=blocks)\n",
    "    lp_block_sem[sim] = util.nd_block_average(remainder, axis=0, func=partial(stats.sem, ddof=1), blocks=blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = False\n",
    "curr_fig_path = Path(\"Figures/kc_block_error\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "corrected_mean_sem = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "\n",
    "    corrected_mean_sem[sim] = np.empty((2, max_q_dict[sim]))\n",
    "\n",
    "    for q in range(0, max_q_dict[sim]):\n",
    "        # Mean with block size 1\n",
    "        corrected_mean_sem[sim][0, q] = block_mean[sim][q][0] \n",
    "        blocked_sem = lp_block_sem[sim][q]\n",
    "        popt, pcov = curve_fit(\n",
    "            correlation_time_sqrt, blocks, blocked_sem / blocked_sem[0]\n",
    "        )\n",
    "        corrected_mean_sem[sim][1, q] = blocked_sem[0]* np.sqrt(2*popt[0])\n",
    "        \n",
    "        ax.plot(\n",
    "            np.log2(blocks),\n",
    "            blocked_sem / blocked_sem[0],\n",
    "            linewidth=NORMAL_LINE,\n",
    "            label=f\"q{q}\",\n",
    "            color=sns.color_palette(\"colorblind\")[q],\n",
    "            linestyle=\":\",\n",
    "        )\n",
    "\n",
    "        ax.plot(\n",
    "            np.log2(blocks),\n",
    "            [correlation_time_sqrt(block, popt) for block in blocks],\n",
    "            linewidth=NORMAL_LINE,\n",
    "            color=sns.color_palette(\"colorblind\")[q],\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(r\"$log_2$(block)\")\n",
    "    ax.set_ylabel(r\"$\\delta X_b/\\delta X_1$\")\n",
    "    ax.set_title(f\"Sys{sim}:{util.system_names[sim]}\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(curr_fig_path/f\"{sim}_block_error.png\", format=\"png\")\n",
    "\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9203f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(4):\n",
    "#     print(f\"q^4h_q ({i}) = {corrected_mean_sem[\"4\"][0]} +- {corrected_mean_sem[\"4\"][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Discard first X% for all trajectories\n",
    "# discard = 10\n",
    "# max_q = 4\n",
    "# blocks = np.arange(1, 2**9 + 1, 1)\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     low_q_data = qfour_spectra[sim][:, 0:max_q]\n",
    "#     # low_q_data = spectra[sim][1][:, 0:max_q]\n",
    "    \n",
    "#     _, remainder = np.split(low_q_data, [int(discard / 100 * len(low_q_data))])\n",
    "\n",
    "#     hq_mean = np.mean(remainder, axis=0)\n",
    "\n",
    "#     util.nd_block_average(remainder, axis=0, func=np.mean, blocks=blocks)\n",
    "#     block_sem = util.nd_block_average(remainder, axis=0, func=partial(stats.sem, ddof=1), blocks=blocks)\n",
    "\n",
    "#     corrected_hq_sem = np.empty((max_q))\n",
    "\n",
    "#     for q in range(max_q):\n",
    "#         blocked_sem = block_sem[q]\n",
    "#         popt, pcov = curve_fit(\n",
    "#             correlation_time_sqrt, blocks, block_sem[q] / block_sem[q][0]\n",
    "#         )\n",
    "#         corrected_hq_sem[q] = block_sem[q][0]* np.sqrt(2*popt[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e216b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "c = cmap(np.linspace(0, 1, len(util.simulations)))\n",
    "\n",
    "kc_mean_std = np.empty((len(util.simulations), 2))\n",
    "\n",
    "# Bootstrap values\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "for i, sim in enumerate(util.simulations):\n",
    "    f_rvs = []\n",
    "\n",
    "    # Construct random Gaussian processe for each wavenumber\n",
    "    for q in range(corrected_mean_sem[sim].shape[1]):\n",
    "        # print(corrected_mean_sem[sim][0, i], corrected_mean_sem[sim][1][i])\n",
    "        r = stats.norm(\n",
    "            loc=corrected_mean_sem[sim][0, q], scale=corrected_mean_sem[sim][1][q]\n",
    "        )\n",
    "        f_rvs.append(r.rvs)\n",
    "    # Run parametric bootstrap with random proceses\n",
    "    boot = util.parametric_bootstrap(f_rvs, n_samples=50000)\n",
    "    \n",
    "    # Fit kcs to bootstrap samples\n",
    "    kcs = 1.0 / np.mean(boot, axis=0)\n",
    "\n",
    "    # Plot distribution of kcs\n",
    "    ax.hist(\n",
    "        kcs,\n",
    "        bins=50,\n",
    "        density=True,\n",
    "        color=c[i],\n",
    "        label=f\"{sim} {util.system_names[sim]}\",\n",
    "    )\n",
    "\n",
    "    kc_mean_std[i] = [np.mean(kcs), np.std(kcs)]\n",
    "\n",
    "    print(\n",
    "        sim, kc_mean_std[i]\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(r\"$K_c$ ($k_BT$)\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "fig.savefig(curr_fig_path / f\"kc_distributions.png\", format=\"png\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = False\n",
    "curr_fig_path = Path(\"Figures/height_spectra_kc\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Discard first X% for all trajectories\n",
    "discard = 10\n",
    "max_q = 100\n",
    "\n",
    "for i, sim in enumerate(util.simulations):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "    low_q_data = qfour_spectra[sim][:, 0:max_q]\n",
    "    # low_q_data = spectra[sim][1][:, 0:max_q]\n",
    "\n",
    "    _, remainder = np.split(low_q_data, [int(discard / 100 * len(low_q_data))])\n",
    "\n",
    "    # Convert to nm^-1\n",
    "    q = spectra[sim][0][0:max_q] * 10\n",
    "    mask = q < kc_low_q * 10\n",
    "\n",
    "    # q^4*hq\n",
    "    hq_mean = np.mean(remainder, axis=0)\n",
    "    hq_std = np.std(remainder, axis=0)\n",
    "\n",
    "\n",
    "    ax.errorbar(q[mask], hq_mean[mask], yerr=hq_std[mask], fmt=\".\", markersize=3, elinewidth=THIN_LINE, ecolor=\"lightgray\")\n",
    "\n",
    "    ax.errorbar(q[~mask], hq_mean[~mask], yerr=hq_std[~mask], color=\"dimgray\", fmt=\".\", markersize=3, elinewidth=THIN_LINE, ecolor=\"lightgray\")\n",
    "\n",
    "    ax.axhline(1/kc_mean_std[i][0], color=\"r\")\n",
    "    # ax.axvline(kc_low_q, color=\"k\", linewidth=0.5, linestyle=\":\")\n",
    "\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.7,\n",
    "        f\"$K_c$ = {kc_mean_std[i][0]:.1f} $\\pm$ {kc_mean_std[i][1]:.1f} $k_BT$\",\n",
    "        color=\"r\",\n",
    "        transform=ax.transAxes\n",
    "    )\n",
    "\n",
    "    # ax.set_xlim(5e-2, 5)\n",
    "    ax.set_ylim(0.0, 0.45)\n",
    "    ax.set_xscale(\"log\")\n",
    "\n",
    "    ax.set_ylabel(r\"$q^4 \\times \\mathrm{intensity}$ (nm$^2$)\")\n",
    "    ax.set_xlabel(r\"$q$ (nm$^{-1}$)\")\n",
    "\n",
    "    ax.set_title(f\"System {sim}: {util.system_names[sim]}\")\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "\n",
    "    fig.savefig(curr_fig_path/f\"{sim}_height_spectra_kc.png\", format=\"png\")\n",
    "\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "        \n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da880ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "c1 = mpl.cm.get_cmap(\"Purples\")(np.linspace(0.2, 0.8, 3))\n",
    "c2 = mpl.cm.get_cmap(\"Reds\")(np.linspace(0.2, 0.8, 3))\n",
    "\n",
    "c3 = np.array([0.2, 0.2, 0.2, 1]).reshape(1, -1)\n",
    "\n",
    "c4 = mpl.cm.get_cmap(\"Blues\")(np.linspace(0.8, 0.2, 2))\n",
    "c5 = mpl.cm.get_cmap(\"Oranges\")(np.linspace(0.8, 0.2, 2))\n",
    "\n",
    "colors = np.vstack((c1, c2, c3, c4, c5))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "ax.bar(\n",
    "    range(kc_mean_std.shape[0]), kc_mean_std[:, 0], color=colors, yerr=kc_mean_std[:, 1]\n",
    ")\n",
    "\n",
    "ax.set_ylabel(r\"$K_c$ ($k_BT$)\")\n",
    "ax.set_xlabel(r\"System\")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticks(),\n",
    ")\n",
    "\n",
    "x_ticks_labels = [f\"{sim}\" for sim in util.simulations]\n",
    "\n",
    "# Set number of ticks for x-axis\n",
    "ax.set_xticks(range(11))\n",
    "# Set ticks labels for x-axis\n",
    "ax.set_xticklabels(x_ticks_labels)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(curr_fig_path / f\"estimated_kcs.png\", format=\"png\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show()\n",
    "\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057bb8f-63c7-4c50-8e3b-bac49147458d",
   "metadata": {},
   "source": [
    "### Statistical Inefficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7189ae3-2232-4576-be6c-1cdcdf9705bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO REGENERATE DATA\n",
    "\n",
    "# _s = 10  # Min block\n",
    "\n",
    "# discards = np.arange(0, 100, 10)  # Percent of data to discard from end\n",
    "# blocks = np.arange(1, 101, 1, dtype=int)\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     print(\"Processing system:\", sim)\n",
    "\n",
    "#     # Populate some basic information\n",
    "#     frame_dt = mc[sim].times[1] - mc[sim].times[0]  # picoseconds\n",
    "\n",
    "#     print(frame_dt)\n",
    "#     _b = 0\n",
    "#     _e = len(mc[sim].frames)\n",
    "#     n_frames = len(range(_b, _e + 1, _s))\n",
    "#     shape = mc[sim].P.shape\n",
    "\n",
    "#     # Times from mdanalysis are unreliable due to restarts\n",
    "#     # times = mc[sys].times[np.arange(0, _e, _s, dtype=int)]\n",
    "#     times = np.arange(0, _e, _s, dtype=int) * frame_dt  # picoseconds\n",
    "\n",
    "#     # Split into chunks and compute kcs\n",
    "#     split_indices = np.arange(_s, _e, _s, dtype=int)\n",
    "#     powers = np.fromiter(\n",
    "#         map(\n",
    "#             partial(np.mean, axis=0),\n",
    "#             np.split(mc[sim].results[\"height_power_spectrum\"], split_indices),\n",
    "#         ),\n",
    "#         dtype=np.dtype((np.double, (shape))),\n",
    "#     )\n",
    "#     kcs = np.fromiter(\n",
    "#         map(partial(fit_kc_from_power, threshold=kc_low_q, mc=mc[sim]), powers),\n",
    "#         dtype=np.double,\n",
    "#     )\n",
    "\n",
    "#     # Plot Kc evaluated over 5ns (0.5 * _s) blocks\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "#     # fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "\n",
    "#     ax.plot(times * 1e-6, kcs)  # Convert to microseconds\n",
    "#     # ax2.plot(times * 1e-6, kcs)  # Convert to microseconds\n",
    "\n",
    "#     # ax1.set_ylim(50, 100)\n",
    "#     # ax2.set_ylim(0, 30)\n",
    "\n",
    "#     # # hide the spines between ax and ax2\n",
    "#     # ax1.spines.bottom.set_visible(False)\n",
    "#     # ax2.spines.top.set_visible(False)\n",
    "#     # ax1.xaxis.tick_top()\n",
    "#     # ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "#     # ax2.xaxis.tick_bottom()\n",
    "\n",
    "#     # # Now, let's turn towards the cut-out slanted lines.\n",
    "#     # # We create line objects in axes coordinates, in which (0,0), (0,1),\n",
    "#     # # (1,0), and (1,1) are the four corners of the axes.\n",
    "#     # # The slanted lines themselves are markers at those locations, such that the\n",
    "#     # # lines keep their angle and position, independent of the axes size or scale\n",
    "#     # # Finally, we need to disable clipping.\n",
    "\n",
    "#     # d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "#     # kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "#     #             linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "#     # ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "#     # ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "#     ax.set_ylabel(r\"$K_c$ ($k_b$T)\")\n",
    "#     ax.set_xlabel(r\"Time (s)\")\n",
    "\n",
    "#     ax.set_title(f\"System {sim}: {util.system_names[sim]}\")\n",
    "\n",
    "#     # fig.tight_layout()\n",
    "#     save_fig(fig, f\"Figures/{sim}_kc_5nsblock\")\n",
    "\n",
    "#     ## Perform block analysis\n",
    "#     kc_mean = kcs.mean()\n",
    "\n",
    "#     SI = {}\n",
    "#     SI[\"discards\"] = discards\n",
    "#     SI[\"blocks\"] = blocks * frame_dt * _s  # picoseconds\n",
    "\n",
    "#     for discard in discards:\n",
    "#         _, r = np.split(kcs, [int(discard / 100 * n_frames)])\n",
    "#         kc_mean = r.mean()\n",
    "\n",
    "#         SI[(discard, \"sigma\")] = np.zeros(len(blocks))\n",
    "#         SI[(discard, \"mean\")] = np.zeros(len(blocks))\n",
    "\n",
    "#         for i, block in enumerate(blocks):\n",
    "#             n = np.floor(len(r) / block)\n",
    "\n",
    "#             split_indices = np.arange(block, len(r), block, dtype=int)\n",
    "#             block_kcs = np.fromiter(\n",
    "#                 map(np.mean, np.split(r, split_indices)), dtype=np.double\n",
    "#             )\n",
    "\n",
    "#             # Truncate number of blocks if not evenly divisible\n",
    "#             if len(r) % block:\n",
    "#                 block_kcs = block_kcs[:-1]\n",
    "\n",
    "#             SI[(discard, \"sigma\")][i] = np.sum((block_kcs - kc_mean) ** 2) / n\n",
    "#             SI[(discard, \"mean\")][i] = np.mean(block_kcs)\n",
    "\n",
    "#     with open(util.analysis_path / f\"{sim}/SI.pickle\", \"wb\") as handle:\n",
    "#         pickle.dump(SI, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load bending modulus statistical inefficiency\n",
    "# SI_kc = {}\n",
    "# for sim in util.simulations:\n",
    "#     with open(util.analysis_path / sim / \"SI.pickle\", \"rb\") as handle:\n",
    "#         SI_kc[sim] = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b13e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Foreshadow percent discard, statistical inefficiency for all systems\n",
    "# si_kc_system = {\n",
    "#     \"1\": (50, 25),\n",
    "#     \"2\": (50, 25),\n",
    "#     \"3\": (50, 25),\n",
    "#     \"4\": (50, 13),\n",
    "#     \"5\": (20, 15),\n",
    "#     \"6\": (20, 15),\n",
    "#     \"7\": (50, 28),\n",
    "#     \"8\": (50, 25),\n",
    "#     \"9\": (50, 25),\n",
    "#     \"10\": (50, 25),\n",
    "#     \"11\": (50, 25),\n",
    "# }\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     print(f\"System {sim} ({util.system_names[sim]}):\")\n",
    "#     print(f\"  statistical inefficiency: {si_kc_system[sim][1]} ns\")\n",
    "#     print(f\"                   discard: {si_kc_system[sim][0]}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     d = SI_kc[sim]\n",
    "#     discards = d[\"discards\"]\n",
    "#     c = cmap(np.linspace(0, 1, len(discards)))\n",
    "\n",
    "#     times = d[\"blocks\"] * 1e-3  # picoseconds -> nanoseconds\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "#     for i, discard in enumerate(discards):\n",
    "#         sigma = d[(discard, \"sigma\")]\n",
    "#         si = times * (sigma / sigma[0])\n",
    "\n",
    "#         if discard == si_kc_system[sim][0]:\n",
    "#             alpha = 1\n",
    "#         else:\n",
    "#             alpha = 0.2\n",
    "#         ax.plot(\n",
    "#             times,\n",
    "#             si,\n",
    "#             color=c[i],\n",
    "#             alpha=alpha,\n",
    "#             linewidth=NORMAL_LINE,\n",
    "#             label=f\"{100-discard}%\",\n",
    "#         )\n",
    "\n",
    "#     ax.axvline(100, color=\"k\", linestyle=\"dotted\", linewidth=THINNER_LINE)\n",
    "#     ax.axhline(\n",
    "#         si_kc_system[sim][1], color=\"k\", linestyle=\"dotted\", linewidth=THINNER_LINE\n",
    "#     )\n",
    "\n",
    "#     ax.set_ylabel(r\"Statistical Inefficiency (ns)\")\n",
    "#     ax.set_xlabel(r\"Bin Width (ns)\")\n",
    "#     ax.set_title(f\"System {sim}: {util.system_names[sim]}\")\n",
    "#     # ax.legend()\n",
    "\n",
    "#     # Shrink current axis by 20%\n",
    "#     box = ax.get_position()\n",
    "#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "#     # Put a legend to the right of the current axis\n",
    "#     ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), title=\"Keep\")\n",
    "\n",
    "#     ax.set_xlim(0, 200)\n",
    "#     ax.set_ylim(0.0, 50)\n",
    "#     # plt.tight_layout()\n",
    "#     save_fig(fig, f\"Figures/{sim}_StatIneff\")\n",
    "#     plt.show()\n",
    "#     fig.clear()\n",
    "#     plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5656e65",
   "metadata": {},
   "source": [
    "### Plots of height power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _s = 10  # Min block\n",
    "# cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "\n",
    "# fig_all, ax_all = plt.subplots(1, 1, figsize=(6, 3))\n",
    "# KB_VALUES = {}\n",
    "# for sim in util.simulations:\n",
    "#     print(\"Processing system:\", sim)\n",
    "#     discard = si_kc_system[sim][0]\n",
    "#     si = si_kc_system[sim][1] * 1e3 / 500  # nanseconds -> picoseconds -> frames\n",
    "\n",
    "#     _, r = np.split(\n",
    "#         mc[sim].results.height_power_spectrum,\n",
    "#         [int(discard / 100 * len(mc[sim].results.height_power_spectrum))],\n",
    "#     )\n",
    "\n",
    "#     m = SI_kc[sim][(discard, \"mean\")][0]\n",
    "#     sigma = SI_kc[sim][(discard, \"sigma\")][0]\n",
    "\n",
    "#     KB_VALUES[sim] = m\n",
    "\n",
    "#     N = len(r)\n",
    "#     stdev = sigma * np.sqrt(si / N)\n",
    "\n",
    "#     print(m, sigma, N, si, stdev)\n",
    "\n",
    "#     c = cmap(np.linspace(0, 1, len(util.simulations)))\n",
    "\n",
    "#     height_spectra = radial_averaging(np.mean(r, axis=0), mc[sim])\n",
    "\n",
    "#     mask = height_spectra[:, 0] < kc_low_q\n",
    "#     height_spectra[:, 0] *= 10  # Convert to nm^-1\n",
    "#     height_spectra_cut = height_spectra[mask, :]\n",
    "#     height_spectra_r = height_spectra[~mask, :]\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "#     ax.scatter(height_spectra_r[:, 0], height_spectra_r[:, 2], color=\"silver\", s=8)\n",
    "#     ax.scatter(height_spectra_cut[:, 0], height_spectra_cut[:, 2], s=8)\n",
    "\n",
    "#     ax.axhline(1 / m, color=\"r\")\n",
    "#     ax.axvline(kc_low_q, color=\"k\", linewidth=0.5, linestyle=\":\")\n",
    "\n",
    "#     ax.set_xlim(5e-2, 2.5)\n",
    "#     ax.set_ylim(0.0, 0.4)\n",
    "#     ax.set_xscale(\"log\")\n",
    "\n",
    "#     ax.text(\n",
    "#         0.1,\n",
    "#         0.2,\n",
    "#         f\"$K_c$ = {m:.1f} $\\pm$ {stdev:.1f} $k_BT$\",\n",
    "#         color=\"r\",\n",
    "#     )\n",
    "\n",
    "#     ax.set_ylabel(r\"$q^4 \\times \\mathrm{intensity}$ (-)\")\n",
    "#     ax.set_xlabel(r\"$q$ (nm$^{-1}$)\")\n",
    "#     ax.set_title(f\"System {sim}: {util.system_names[sim]}\")\n",
    "#     fig.set_tight_layout(True)\n",
    "\n",
    "#     save_fig(fig, f\"Figures/{sim}_kc\")\n",
    "#     # plt.show()\n",
    "#     # fig.clear()\n",
    "#     # plt.close(fig)\n",
    "\n",
    "#     ax_all.scatter(\n",
    "#         height_spectra[:, 0],\n",
    "#         height_spectra[:, 2],\n",
    "#         color=c[int(sim) - 1],\n",
    "#         label=f\"System {sim} {util.system_names[sim]}\",\n",
    "#     )\n",
    "\n",
    "# # Shrink current axis by 20%\n",
    "# box = ax_all.get_position()\n",
    "# ax_all.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# # Put a legend to the right of the current axis\n",
    "# ax_all.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# ax_all.set_xlim(5e-2, 2.5)\n",
    "# ax_all.set_ylim(0.0, 0.4)\n",
    "# ax_all.set_xscale(\"log\")\n",
    "# ax_all.set_ylabel(r\"$q^4 \\times \\mathrm{intensity}$ (-)\")\n",
    "# ax_all.set_xlabel(r\"$q$ (nm$^{-1}$)\")\n",
    "# fig_all.set_tight_layout(True)\n",
    "# save_fig(fig_all, \"height_spectrum-all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc539b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# temp_kc = np.empty((len(util.simulations), 2))\n",
    "# for i, sim in enumerate(util.simulations):\n",
    "#     discard = si_kc_system[sim][0]\n",
    "#     si = si_kc_system[sim][1] * 1e3 / 500  # nanseconds -> picoseconds -> frames\n",
    "#     _, r = np.split(\n",
    "#         mc[sim].results.height_power_spectrum,\n",
    "#         [int(discard / 100 * len(mc[sim].results.height_power_spectrum))],\n",
    "#     )\n",
    "    \n",
    "#     m = SI_kc[sim][(discard, \"mean\")][0]\n",
    "#     sigma = SI_kc[sim][(discard, \"sigma\")][0]\n",
    "\n",
    "#     N = len(r)\n",
    "#     stdev = sigma * np.sqrt(si / N)\n",
    "\n",
    "#     temp_kc[i] = [m, stdev]\n",
    "    \n",
    "# np.savetxt(\"sheets/kb.csv\", temp_kc, delimiter=\",\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b25dc4",
   "metadata": {},
   "source": [
    "# Neighbor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "# Lipids in order in results matrix\n",
    "lipids = [\"POPC\", \"DOPC\", \"POPE\", \"DOPE\", \"CDL1\", \"POPG\", \"DOPG\"]\n",
    "lipid_dict = dict([[j, i] for i, j in enumerate(lipids)])\n",
    "leaflets = [\"upper\", \"lower\"]\n",
    "\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)\n",
    "\n",
    "\n",
    "def print_neighbor_analysis(dataset, prefix=\"\"):\n",
    "    for sim in util.simulations:\n",
    "        print(f\"System {sim}: {util.system_names[sim]}\")\n",
    "\n",
    "        raw_baseline = []\n",
    "        baseline = []\n",
    "        s = \"\"\n",
    "        for lipid in lipids:\n",
    "            if lipid in compositions[sim, \"raw_composition\"]:\n",
    "                # div by 2 to account for leaflet composition\n",
    "                raw_baseline.append(compositions[sim, \"raw_composition\"][lipid] / 2)\n",
    "            else:\n",
    "                raw_baseline.append(0)\n",
    "            s += f\"{lipid}: {compositions[sim, 'normed_composition'][lipid]:0.3f}, \"\n",
    "            baseline.append(compositions[sim, \"normed_composition\"][lipid])\n",
    "        raw_baseline = np.array(raw_baseline).reshape(-1, 1)  # COLUMN VECTOR\n",
    "        print(s)\n",
    "        # fraction of each lipid per leaflet\n",
    "        baseline = np.array(baseline)\n",
    "        # print(raw_baseline, baseline)\n",
    "\n",
    "        # Aggregate statistics from both leaflets\n",
    "        counts_per_frame = (dataset[sim][\"upper\"] + dataset[sim][\"lower\"]) / 2\n",
    "        # Keep only back half of trajectory\n",
    "        N = int(0.5 * len(counts_per_frame))\n",
    "        counts = np.mean(counts_per_frame[N:-1], axis=0)  # mean counts per frame\n",
    "\n",
    "        # Copy counts across diagonal which must be symmetric\n",
    "        for i in range(0, len(lipids)):\n",
    "            for j in range(0, i):\n",
    "                counts[i, j] = counts[j, i]\n",
    "            counts[i, i] *= 2\n",
    "        counts /= 2\n",
    "\n",
    "        # print(pd.DataFrame(counts, columns=lipids, index=lipids))\n",
    "\n",
    "        # Normalize by number of each lipid within leaflet\n",
    "        # ROWWISE DIVISION...\n",
    "        normed_counts = np.divide(\n",
    "            counts, raw_baseline, out=np.zeros_like(counts), where=raw_baseline != 0\n",
    "        )\n",
    "        df_normed_counts = pd.DataFrame(normed_counts, columns=lipids, index=lipids)\n",
    "        print(\"# of each lipid around row lipid\\n\", df_normed_counts)\n",
    "\n",
    "        rowwise_sum = np.sum(normed_counts, axis=1).reshape(-1, 1)\n",
    "        # print(np.array2string(rowwise_sum, max_line_width=np.inf))\n",
    "\n",
    "        likelihood_count = np.divide(\n",
    "            normed_counts,\n",
    "            rowwise_sum,\n",
    "            out=np.zeros_like(counts),\n",
    "            where=rowwise_sum != 0,\n",
    "        )\n",
    "\n",
    "        # print(np.array2string(likelihood_count, max_line_width=np.inf))\n",
    "\n",
    "        diff_counts = np.divide(\n",
    "            likelihood_count,\n",
    "            baseline,\n",
    "            out=np.zeros_like(normed_counts),\n",
    "            where=baseline != 0,\n",
    "        )\n",
    "        # df = pd.DataFrame(normed_counts, columns=lipids, index=lipids)\n",
    "        # print(df)\n",
    "\n",
    "        # print(\"DIFF:\")\n",
    "        df_diff = pd.DataFrame(pd.DataFrame(diff_counts, columns=lipids, index=lipids))\n",
    "\n",
    "        df_diff.to_csv(f\"sheets/sim_{sim}_likelihood_{prefix}.csv\")\n",
    "\n",
    "        print(\"Enrichment from likelihood:\\n\", df_diff)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_enrichment = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    with open(\n",
    "        util.analysis_path / f\"{sim}/neighbor_enrichment_leaflet_glo.pickle\", \"rb\"\n",
    "    ) as handle:\n",
    "        neighbor_enrichment[sim] = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8cf045",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_neighbor_analysis(neighbor_enrichment, prefix=\"15A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5522b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    with open(util.analysis_path / f\"{sim}/voronoi_leaflet_glo.pickle\", \"rb\") as handle:\n",
    "        voronoi[sim] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f639a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_neighbor_analysis(voronoi, prefix=\"voronoi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64792c",
   "metadata": {},
   "source": [
    "# Lateral Pressures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5378ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_cubic_np(z, lp, minz=None, maxz=None, maxiter=5000, sym: bool = True):\n",
    "    \"\"\"\n",
    "    Compute the first moment using a cubic piecewise interpolant and Gaussian quadrature\n",
    "    \"\"\"\n",
    "    lp = lp / 1e3  # to convert to piconewtons / nm^2\n",
    "\n",
    "    if sym:\n",
    "        if len(lp) % 2 == 1:\n",
    "            s = int(np.floor(len(lp) / 2))\n",
    "            bot, mid, top = np.split(lp, [s, s + 1])\n",
    "            sym_top = (np.flip(bot) + top) / 2\n",
    "            sym_bot = np.flip(sym_top)\n",
    "            lp = np.hstack((sym_bot, mid, sym_top))\n",
    "        else:\n",
    "            bot, top = np.split(lp, 2)\n",
    "            sym_top = (np.flip(bot) + top) / 2\n",
    "            sym_bot = np.flip(sym_top)\n",
    "            lp = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "    y = lp * z\n",
    "\n",
    "    if minz is None:\n",
    "        minz = min(z)\n",
    "    if maxz is None:\n",
    "        maxz = max(z)\n",
    "\n",
    "    approx = interpolate.interp1d(z, y, kind=\"cubic\")  # interpolating a function\n",
    "    intg = integrate.quadrature(\n",
    "        approx, minz, maxz, maxiter=maxiter\n",
    "    )  # finding the integral over bounds\n",
    "    return intg\n",
    "\n",
    "\n",
    "def zero_cubic_np(z, lp, minz=None, maxz=None, maxiter=5000, sym: bool = True):\n",
    "    \"\"\"\n",
    "    Compute the zeroeth moment using a cubic piecewise interpolant and Gaussian quadrature\n",
    "    \"\"\"\n",
    "    # p = data['LP_(kPA)']/1e15 # to convert to newtons / nm^2\n",
    "    lp = lp / 1e3  # to convert to piconewtons / nm^2\n",
    "\n",
    "    if sym:\n",
    "        if len(lp) % 2 == 1:\n",
    "            s = int(np.floor(len(lp) / 2))\n",
    "            bot, mid, top = np.split(lp, [s, s + 1])\n",
    "            sym_top = (np.flip(bot) + top) / 2\n",
    "            sym_bot = np.flip(sym_top)\n",
    "            lp = np.hstack((sym_bot, mid, sym_top))\n",
    "        else:\n",
    "            bot, top = np.split(lp, 2)\n",
    "            sym_top = (np.flip(bot) + top) / 2\n",
    "            sym_bot = np.flip(sym_top)\n",
    "            lp = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "    if minz is None:\n",
    "        minz = min(z)\n",
    "    if maxz is None:\n",
    "        maxz = max(z)\n",
    "\n",
    "    approx = interpolate.interp1d(z, lp, kind=\"cubic\")  # interpolating a function\n",
    "    intg = integrate.quadrature(\n",
    "        approx, minz, maxz, maxiter=maxiter\n",
    "    )  # finding the integral over bounds\n",
    "    return intg\n",
    "\n",
    "\n",
    "def mean_squared_deviation_np(data: npt.ArrayLike) -> float:\n",
    "    \"\"\"\n",
    "    Compute the mean squared deviation of the data\n",
    "    \"\"\"\n",
    "    return sum(data ** 2) / (data.size - 1)\n",
    "\n",
    "\n",
    "def max_difference(a: npt.ArrayLike, b: npt.ArrayLike):\n",
    "    \"\"\"\n",
    "    Get the max difference between two equal sized arrays\n",
    "    \"\"\"\n",
    "    if a.size != b.size:\n",
    "        raise RuntimeError(\"a and b must be same sized arrays\")\n",
    "    diff = np.abs(a - b)\n",
    "    return np.amax(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3970fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def first_cubic(data, minz=None, maxz=None, maxiter=5000, sym: bool = True):\n",
    "#     \"\"\"\n",
    "#     Compute the first moment using a cubic piecewise interpolant and Gaussian quadrature\n",
    "#     \"\"\"\n",
    "#     x = data[\"z\"]  # in nanometers\n",
    "#     # p = data['LP_(kPA)']/1e15 #to convert to newtons / nm^2\n",
    "#     p = data[\"LP_(kPA)\"].values / 1e3  # to convert to piconewtons / nm^2\n",
    "\n",
    "#     if sym:\n",
    "#         if len(p) % 2 == 1:\n",
    "#             s = int(np.floor(len(p) / 2))\n",
    "#             bot, mid, top = np.split(p, [s, s + 1])\n",
    "#             sym_top = (np.flip(bot) + top) / 2\n",
    "#             sym_bot = np.flip(sym_top)\n",
    "#             p = np.hstack((sym_bot, mid, sym_top))\n",
    "#         else:\n",
    "#             bot, top = np.split(p, 2)\n",
    "#             sym_top = (np.flip(bot) + top) / 2\n",
    "#             sym_bot = np.flip(sym_top)\n",
    "#             p = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "#     y = p * x\n",
    "\n",
    "#     if minz is None:\n",
    "#         minz = min(x)\n",
    "#     if maxz is None:\n",
    "#         maxz = max(x)\n",
    "\n",
    "#     approx = interpolate.interp1d(x, y, kind=\"cubic\")  # interpolating a function\n",
    "#     intg = integrate.quadrature(\n",
    "#         approx, minz, maxz, maxiter=maxiter\n",
    "#     )  # finding the integral over bounds\n",
    "#     return intg\n",
    "\n",
    "\n",
    "# def zero_cubic(data, minz=None, maxz=None, maxiter=5000, sym: bool = True):\n",
    "#     \"\"\"\n",
    "#     Compute the zeroeth moment using a cubic piecewise interpolant and Gaussian quadrature\n",
    "#     \"\"\"\n",
    "#     x = data[\"z\"]  # in nanometers\n",
    "#     # p = data['LP_(kPA)']/1e15 # to convert to newtons / nm^2\n",
    "#     p = data[\"LP_(kPA)\"].values / 1e3  # to convert to piconewtons / nm^2\n",
    "\n",
    "#     if sym:\n",
    "#         if len(p) % 2 == 1:\n",
    "#             s = int(np.floor(len(p) / 2))\n",
    "#             bot, mid, top = np.split(p, [s, s + 1])\n",
    "#             sym_top = (np.flip(bot) + top) / 2\n",
    "#             sym_bot = np.flip(sym_top)\n",
    "#             p = np.hstack((sym_bot, mid, sym_top))\n",
    "#         else:\n",
    "#             bot, top = np.split(p, 2)\n",
    "#             sym_top = (np.flip(bot) + top) / 2\n",
    "#             sym_bot = np.flip(sym_top)\n",
    "#             p = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "#     if minz is None:\n",
    "#         minz = min(x)\n",
    "#     if maxz is None:\n",
    "#         maxz = max(x)\n",
    "\n",
    "#     approx = interpolate.interp1d(x, p, kind=\"cubic\")  # interpolating a function\n",
    "#     intg = integrate.quadrature(\n",
    "#         approx, minz, maxz, maxiter=maxiter\n",
    "#     )  # finding the integral over bounds\n",
    "#     return intg\n",
    "\n",
    "# def mean_squared_deviation(data: pd.DataFrame, var: str = \"Szz\") -> float:\n",
    "#     \"\"\"\n",
    "#     Compute the mean squared deviation of the data\n",
    "#     \"\"\"\n",
    "#     return sum(data[var] ** 2) / (data[var].size - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LStensor import LStensor\n",
    "\n",
    "lateral_pressure = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    fd = Path(util.analysis_path /  f\"{sim}_small/stress_calc/frames/frame{i}.dat0\")\n",
    "    field = LStensor(2)\n",
    "    field.g_loaddata(files=[fd], bAvg=\"avg\")\n",
    "\n",
    "    # stress_tensor = np.empty((20000, field.nz, 9))\n",
    "    lateral_pressure[sim] = np.empty((20000, field.nz, 3))\n",
    "\n",
    "    # 0-20000 frames in each trajectory\n",
    "    for i, j in enumerate(range(1, 20001)):\n",
    "        fd = Path(util.analysis_path / f\"{sim}_small/stress_calc/frames/frame{j}.dat0\")\n",
    "        field = LStensor(2)\n",
    "        field.g_loaddata(files=[fd], bAvg=\"avg\")\n",
    "        stress_tensor = field.data_grid * 100   # Convert to kPa from 10^5 Pa\n",
    "        # Sxx Sxy Sxz Syx Syy Syz Szx Szy Szz\n",
    "        # 0               4               8\n",
    "\n",
    "        pXY = -0.5*(stress_tensor[:,0] + stress_tensor[:,4]).reshape(-1,1)\n",
    "        pN = (-stress_tensor[:,8]).reshape(-1,1)\n",
    "        lp = pXY - pN\n",
    "        z = (np.arange(field.nz) * field.dz - (field.nz - 1) * field.dz / 2).reshape(-1,1)\n",
    "        lateral_pressure[sim][i] = np.hstack((pN, lp, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard first X% for all trajectories\n",
    "discard = 10\n",
    "blocks = np.arange(1, 2**8 + 1, 1)\n",
    "\n",
    "lp_block_var = {}\n",
    "lp_block_sem = {}\n",
    "lp_block_mean = {}\n",
    "for sim in util.simulations:\n",
    "    data = lateral_pressure[sim][:,:, 1]\n",
    "    nT, nZs= data.shape\n",
    "\n",
    "    lp_block_mean[sim] = np.zeros((nZs, len(blocks)))\n",
    "    lp_block_var[sim] = np.zeros((nZs, len(blocks)))\n",
    "    lp_block_sem[sim] = np.zeros((nZs, len(blocks)))\n",
    "    \n",
    "    _, remainder = np.split(data, [int(discard / 100 * len(data))])\n",
    "\n",
    "    lp_block_mean[sim] = util.nd_block_average(remainder, axis=0, func=np.mean, blocks=blocks)\n",
    "    lp_block_var[sim] = util.nd_block_average(remainder, axis=0, func=partial(np.var, ddof=1), blocks=blocks)\n",
    "    lp_block_sem[sim] = util.nd_block_average(remainder, axis=0, func=partial(stats.sem, ddof=1), blocks=blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lateral_pressure[\"1\"][:, :, 1][:, 105]\n",
    "print(len(data))\n",
    "result = np.correlate(data, data, mode='full')\n",
    "plt.plot(result[int(result.size/2):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cf8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in util.simulations:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "    ax.errorbar(np.mean(lateral_pressure[sim], axis=0)[:, 2], lp_block_mean[sim][:,0], yerr=np.sqrt(lp_block_var[sim][:,0]), color=\"b\", linewidth=THIN_LINE,ecolor=\"lightgray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27076071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sim in util.simulations:\n",
    "    # print(sim, lateral_pressure[sim][:,:,1].shape)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "\n",
    "    for i in range(50, 150):\n",
    "        data = lateral_pressure[sim][:,:,1]\n",
    "\n",
    "        ax.plot(\n",
    "            range(len(data[:, i])),\n",
    "            data[:, i], \n",
    "            linewidth=NORMAL_LINE,\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(r\"Frame\")\n",
    "    ax.set_ylabel(r\"Pressure\")\n",
    "    ax.set_title(f\"Sys{sim}:{util.system_names[sim]}\")\n",
    "\n",
    "    # ax.legend(loc=\"upper right\")\n",
    "\n",
    "    # # Shrink current axis by 20%\n",
    "    # box = ax.get_position()\n",
    "    # ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # # Put a legend to the right of the current axis\n",
    "    # ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a436e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures/lp_block_analysis\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lp_corrected_mean_sem = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    nZs, nBlock = lp_block_mean[sim].shape\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "\n",
    "    lp_corrected_mean_sem[sim] = np.empty((2, nZs))\n",
    "\n",
    "    for z in range(100,105): #nZs):\n",
    "        # Mean with block size 1\n",
    "        lp_corrected_mean_sem[sim][0, z] = lp_block_mean[sim][z][0] \n",
    "        blocked_sem = lp_block_sem[sim][z]\n",
    "        block_var = lp_block_var[sim][z]\n",
    "\n",
    "        # popt, pcov = curve_fit(\n",
    "        #     correlation_time_sqrt, blocks, blocked_sem / blocked_sem[0]\n",
    "        # )\n",
    "        # lp_corrected_mean_sem[sim][1, z] = blocked_sem[0]* np.sqrt(2*popt[0])\n",
    "        \n",
    "        ax.plot(\n",
    "            np.log2(blocks),\n",
    "            # blocked_sem / blocked_sem[0],\n",
    "            blocks * (block_var / block_var[0]),\n",
    "            linewidth=NORMAL_LINE,\n",
    "            # label=f\"q{q}\",\n",
    "            # color=sns.color_palette(\"colorblind\")[q],\n",
    "            linestyle=\":\",\n",
    "        )\n",
    "\n",
    "        # ax.plot(\n",
    "        #     np.log2(blocks),\n",
    "        #     [correlation_time_sqrt(block, popt) for block in blocks],\n",
    "        #     linewidth=NORMAL_LINE,\n",
    "        #     # color=sns.color_palette(\"colorblind\")[q],\n",
    "        # )\n",
    "\n",
    "    ax.set_xlabel(r\"$log_2$(block)\")\n",
    "    ax.set_ylabel(r\"$\\delta X_b/\\delta X_1$\")\n",
    "    ax.set_title(f\"Sys{sim}:{util.system_names[sim]}\")\n",
    "    # ax.legend(loc=\"upper left\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # fig.savefig(curr_fig_path/f\"{sim}_lp_block_error.png\", format=\"png\")\n",
    "\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fafb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 11, figsize=(12, 8), sharex=True, sharey=True)\n",
    "for sim in util.simulations:\n",
    "    ax_index = int(sim) - 1\n",
    "    ax[ax_index].axhline(0, linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "    data = np.mean(lateral_pressure[sim], axis=0)\n",
    "    z = data[:, 2]\n",
    "\n",
    "    ax[ax_index].plot(\n",
    "        data[:,0] * 0.01,\n",
    "        z,\n",
    "        label=\"Normal Stress\",\n",
    "        linewidth=NORMAL_LINE,\n",
    "        linestyle=\"-\",\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "    lateral = data[:,1] * 0.01 # bar\n",
    "\n",
    "    # Symmetrizing\n",
    "    if len(lateral) % 2 == 1:\n",
    "        s = int(np.floor(len(lateral) / 2))\n",
    "        bot, mid, top = np.split(lateral, [s, s + 1])\n",
    "        sym_top = (np.flip(bot) + top) / 2\n",
    "        sym_bot = np.flip(sym_top)\n",
    "        sym_lp = np.hstack((sym_bot, mid, sym_top))\n",
    "    else:\n",
    "        bot, top = np.split(lateral, 2)\n",
    "        sym_top = (np.flip(bot) + top) / 2\n",
    "        sym_bot = np.flip(sym_top)\n",
    "        sym_lp = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "    ax[ax_index].fill_betweenx(z, sym_lp, 0, label=\"Lateral Pressure\", alpha=0.4)\n",
    "\n",
    "    ax[ax_index].set_ylim(-4, 4)\n",
    "    # ax[x,y].ticklabel_format(axis = 'x', style = 'sci', scilimits = (0,0))\n",
    "    ax[ax_index].set_xlabel(\"S or P (bar)\")\n",
    "    ax[ax_index].set_title(f\"{util.system_names[sim]}\", rotation=45)\n",
    "    if ax_index == 0:\n",
    "        ax[ax_index].set_ylabel(\"Z (nm)\")\n",
    "\n",
    "# handles = [\n",
    "#     mlines.Line2D([], [], color=\"black\", linestyle=\":\", label=\"Normal Stress\"),\n",
    "#     mlines.Line2D(\n",
    "#         [],\n",
    "#         [],\n",
    "#         color=\"black\",\n",
    "#         linestyle=\"-\",\n",
    "#         label=\"Lateral Stress\",\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "# plt.legend(handles=handles, bbox_to_anchor=(-2.5, -0.95, 0.8, 0.8), ncol=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig.savefig(curr_fig_path / \"stress.png\", format=\"png\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86a94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 11, figsize=(12, 8), sharex=True, sharey=True)\n",
    "for sim in util.simulations:\n",
    "    ax_index = int(sim) - 1\n",
    "    ax[ax_index].axhline(0, linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "    data = np.mean(lateral_pressure[sim], axis=0)\n",
    "    z = data[:, 2]\n",
    "\n",
    "    lateral = data[:,1] / 1e3 # pN/nm^2\n",
    "    # Symmetrizing\n",
    "    if len(lateral) % 2 == 1:\n",
    "        s = int(np.floor(len(lateral) / 2))\n",
    "        bot, mid, top = np.split(lateral, [s, s + 1])\n",
    "        sym_top = (np.flip(bot) + top) / 2\n",
    "        sym_bot = np.flip(sym_top)\n",
    "        sym_lp = np.hstack((sym_bot, mid, sym_top))\n",
    "    else:\n",
    "        bot, top = np.split(lateral, 2)\n",
    "        sym_top = (np.flip(bot) + top) / 2\n",
    "        sym_bot = np.flip(sym_top)\n",
    "        sym_lp = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "    ax[ax_index].fill_betweenx(z, z*sym_lp, 0, label=\"Lateral Stress\", alpha=0.4)\n",
    "\n",
    "    ax[ax_index].set_ylim(-4, 4)\n",
    "    # ax[x,y].ticklabel_format(axis = 'x', style = 'sci', scilimits = (0,0))\n",
    "    ax[ax_index].set_xlabel(\"z L_p (pN/nm)\")\n",
    "    ax[ax_index].set_title(f\"{util.system_names[sim]}\", rotation=45)\n",
    "    if ax_index == 0:\n",
    "        ax[ax_index].set_ylabel(\"Z (nm)\")\n",
    "\n",
    "# handles = [\n",
    "#     mlines.Line2D([], [], color=\"black\", linestyle=\":\", label=\"Normal Stress\"),\n",
    "#     mlines.Line2D(\n",
    "#         [],\n",
    "#         [],\n",
    "#         color=\"black\",\n",
    "#         linestyle=\"-\",\n",
    "#         label=\"Lateral Stress\",\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "# plt.legend(handles=handles, bbox_to_anchor=(-2.5, -0.95, 0.8, 0.8), ncol=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(curr_fig_path / \"first_mom_integrand.png\", format=\"png\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cubic_dat = {}\n",
    "z_cubic_dat = {}\n",
    "msd_dat = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    try:\n",
    "        data = np.mean(lateral_pressure[sim], axis=0)\n",
    "\n",
    "        z = data[:, 2]\n",
    "        lp = data[:, 1]\n",
    "        szz = data[:, 0]\n",
    "\n",
    "        fcd = first_cubic_np(z, lp)\n",
    "        f_cubic_dat[sim] = (\n",
    "            first_cubic_np(z, lp, maxz=0)[0] - first_cubic_np(z, lp, minz=0)[0]\n",
    "        ) / 2\n",
    "        # print(first_cubic(z, lp, minz=0)[0], first_cubic(z, lp, maxz=0)[0])\n",
    "\n",
    "        zcd = zero_cubic_np(z, lp)\n",
    "        z_cubic_dat[sim] = zero_cubic_np(z, lp)[0]\n",
    "\n",
    "        msd = mean_squared_deviation_np(szz)\n",
    "        msd_dat[sim] = msd\n",
    "        print(\n",
    "            f\"{util.system_names[sim]}\\n\" f\"   Zero Moment (pN/nm): {zcd}\\n\",\n",
    "            f\"     First Moment (pN): {fcd}\\n\",\n",
    "            f\"Monlayer First Moment (pN): {f_cubic_dat[sim]} {first_cubic_np(z, lp, maxz=0)[0]} {first_cubic_np(z, lp, minz=0)[0]}\\n\",\n",
    "            f\"           MSD (kPa^2): {msd}\\n\",\n",
    "            f\" Upper Leaflet Tension: {zero_cubic_np(z, lp, minz=0)}\\n\",\n",
    "            f\" Lower Leaflet Tension: {zero_cubic_np(z, lp, maxz=0)}\\n\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"{util.system_names[sim]}\\n\" f\"{e}\\n\",\n",
    "        )\n",
    "np.save(\"f_cubic_dat.npy\", f_cubic_dat)\n",
    "np.save(\"z_cubic_dat.npy\", z_cubic_dat)\n",
    "np.save(\"msd_dat.npy\", msd_dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_cubic_dat = {}\n",
    "# z_cubic_dat = {}\n",
    "# msd_dat = {}\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     file = util.analysis_path / f\"{sim}_small/stress_calc/lateral_pressure.csv\"\n",
    "\n",
    "#     try:\n",
    "#         data = pd.read_csv(file)\n",
    "\n",
    "#         fcd = first_cubic(data)\n",
    "#         f_cubic_dat[sim] = (\n",
    "#             first_cubic(data, maxz=0)[0] - first_cubic(data, minz=0)[0]\n",
    "#         ) / 2\n",
    "#         # print(first_cubic(data, minz=0)[0], first_cubic(data, maxz=0)[0])\n",
    "\n",
    "#         zcd = zero_cubic(data)\n",
    "#         z_cubic_dat[sim] = zero_cubic(data)[0]\n",
    "\n",
    "#         msd = mean_squared_deviation(data, \"Szz\")\n",
    "#         msd_dat[sim] = msd\n",
    "#         print(\n",
    "#             f\"{util.system_names[sim]}\\n\" f\"   Zero Moment (pN/nm): {zcd}\\n\",\n",
    "#             f\"     First Moment (pN): {fcd}\\n\",\n",
    "#             f\"Monlayer First Moment (pN): {f_cubic_dat[sim]}\\n\",\n",
    "#             f\"           MSD (kPa^2): {msd}\\n\",\n",
    "#             f\" Upper Leaflet Tension: {zero_cubic(data, minz=0)}\\n\",\n",
    "#             f\" Lower Leaflet Tension: {zero_cubic(data, maxz=0)}\\n\",\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(\n",
    "#             f\"{util.system_names[sim]}\\n\" f\"{e}\\n\",\n",
    "#         )\n",
    "# np.save(\"f_cubic_dat.npy\", f_cubic_dat)\n",
    "# np.save(\"z_cubic_dat.npy\", z_cubic_dat)\n",
    "# np.save(\"msd_dat.npy\", msd_dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.axhline(0, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "ax.scatter(\n",
    "    np.arange(0, 2),\n",
    "    [z_cubic_dat[k] for k in [\"8\", \"9\"]],\n",
    "    label=\"+CDL\",\n",
    "    marker=\"s\",\n",
    "    s=6**2,\n",
    ")\n",
    "ax.scatter(\n",
    "    np.arange(0, 2),\n",
    "    [z_cubic_dat[k] for k in [\"10\", \"11\"]],\n",
    "    label=\"-CDL\",\n",
    "    s=8**2,\n",
    ")\n",
    "\n",
    "# ax.set_ylim(-2, 4)\n",
    "ax.set_ylabel(\"0th mom. (pN/nm)\")\n",
    "# ax.tick_params(axis = 'y', labelcolor = 'darkorange')\n",
    "# ax.set_xlim(0, 25)\n",
    "ax.set_xticks([0, 1], labels=[\"PO\", \"DO\"])\n",
    "# plt.xscale('log')\n",
    "ax.set_xlabel(\"Saturation\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "save_fig(fig, \"Figures/zero_moment\")\n",
    "\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904609dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# ax.axhline(0, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "ax.scatter(\n",
    "    np.arange(0, 2),\n",
    "    [f_cubic_dat[k] for k in [\"8\", \"9\"]],\n",
    "    label=\"+CDL\",\n",
    "    marker=\"s\",\n",
    "    s=6**2,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.scatter(\n",
    "    np.arange(0, 2),\n",
    "    [f_cubic_dat[k] for k in [\"10\", \"11\"]],\n",
    "    label=\"-CDL\",\n",
    "    s=8**2,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "# ax.set_ylim(-2, 4)\n",
    "ax.set_ylabel(\"1st mom. (pN)\")\n",
    "# ax.tick_params(axis = 'y', labelcolor = 'darkorange')\n",
    "# ax.set_xlim(0, 25)\n",
    "ax.set_xticks([0, 1], labels=[\"PO\", \"DO\"])\n",
    "# plt.xscale('log')\n",
    "ax.set_xlabel(\"Saturation\")\n",
    "\n",
    "plt.legend(loc=\"center\")\n",
    "plt.tight_layout()\n",
    "save_fig(fig, \"Figures/first_moment\")\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63905e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# ax.axhline(0, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "ax.scatter(\n",
    "    np.arange(1, 12),\n",
    "    [f_cubic_dat[k] for k in util.simulations],\n",
    "    marker=\"s\",\n",
    "    s=6**2,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "# ax.set_ylim(-2, 4)\n",
    "ax.set_ylabel(\"1st mom. (pN)\")\n",
    "# ax.tick_params(axis = 'y', labelcolor = 'darkorange')\n",
    "ax.set_xlabel(\"System\")\n",
    "ax.set_xticks(np.arange(1, 12, 1))\n",
    "\n",
    "# plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "save_fig(fig, \"Figures/first_moment_all\")\n",
    "plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfcaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in util.simulations:\n",
    "    print(f\"System {sim} c0: {f_cubic_dat[sim]/(kc_mean_std[int(sim)-1][0] * 4.18336647): 0.3f} nm^-1;\", 1 / (f_cubic_dat[sim]/(kc_mean_std[int(sim)-1][0] * 4.18336647)), \"nm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.loadtxt(\"sheets/kb.csv\", delimiter=\",\")\n",
    "# print(data)\n",
    "\n",
    "\n",
    "# tdata = np.empty((5, 2))\n",
    "# for i, v in enumerate([10, 9, 3, 4, 5]):\n",
    "#     tdata[i] = data[v]\n",
    "#     print(util.system_names[str(v + 1)])\n",
    "# print(tdata)\n",
    "# names = [f\"System {i}\" for i in range(1, 6)]\n",
    "# print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd012b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 5))  # sharex=True,\n",
    "# ax.bar(names, tdata[:, 0], yerr=tdata[:, 1])\n",
    "# ax.set_ylabel(r\"Bending modulus ($k_BT$)\")\n",
    "\n",
    "# save_fig(fig, f\"Figures/temp_kb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e100c11",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f500b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ca4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in f_cubic_dat.items():\n",
    "    print(f\"{k}\t{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ca4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in f_cubic_dat.items():\n",
    "    print(f\"{k}\t{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for sim in util.simulations:\n",
    "    top = util.sim_path / f\"{sim}_small\" / \"system.top\"\n",
    "    # print(top.exists())\n",
    "    shutil.copy(top, util.analysis_path / f\"{sim}_small\" )\n",
    "    gro = util.sim_path / f\"{sim}_small\" / \"production3.gro\"\n",
    "    # print(gro.exists())\n",
    "    shutil.copy(gro, util.analysis_path / f\"{sim}_small\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118cfb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda",
   "language": "python",
   "name": "mda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "758e6dc3310fc4113a14db5c9af04d510b7dde461179a1a88c244d629ae14de1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
