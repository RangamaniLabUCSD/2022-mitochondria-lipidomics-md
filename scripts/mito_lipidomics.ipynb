{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b9284b-ceef-492f-b74e-9d08f77cc17f",
   "metadata": {},
   "source": [
    "# Analysis of material properties of mitochondrial membranes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba281424-90c8-460a-869f-425a2cf33323",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d158fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98cba19-8b79-44a2-b05a-37d9638da0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib Version: 3.6.2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%autoreload 1\n",
    "import pickle\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import MDAnalysis\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.typing as npt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import integrate, interpolate, stats\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "%aimport util\n",
    "from plot_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfcc1e19-ebee-4b37-bcc5-c04937953f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_averaging(power2D, mc, min_bin=0.001, max_bin=1, bin_width=0.001):\n",
    "    \"\"\"\n",
    "    Radially average the power spectrum to obtain values. Notably the natural freqeuncy unit\n",
    "    of this function is A^-1.\n",
    "\n",
    "    Args:\n",
    "        power2D (numpy.array((N,N))): Power spectrum\n",
    "        mc (_type_): Membrane curvature object with metadata\n",
    "        min_bin (float, optional): Minimum bin value. Defaults to 0.001.\n",
    "        max_bin (int, optional): Maximum bin value. Defaults to 1.\n",
    "        bin_width (float, optional): Bin width. Defaults to 0.001.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Binned power spectra\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(mc['qx'], mc['qy'])  # A^-1\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    bins = np.arange(min_bin, max_bin, bin_width)\n",
    "\n",
    "    digitized = np.digitize(r, bins)\n",
    "    bc = np.array(\n",
    "        [\n",
    "            r[digitized == i].mean() if np.count_nonzero(digitized == i) else np.NAN\n",
    "            for i in range(1, len(bins))\n",
    "        ]\n",
    "    )\n",
    "    bm = np.array(\n",
    "        [\n",
    "            power2D[digitized == i].mean()\n",
    "            if np.count_nonzero(digitized == i)\n",
    "            else np.NAN\n",
    "            for i in range(1, len(bins))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    bin_centers = bc[np.isfinite(bm)]\n",
    "    bin_means = bm[np.isfinite(bm)]\n",
    "\n",
    "    return np.column_stack((bin_centers, bin_means, bin_centers**4 * bin_means))\n",
    "\n",
    "\n",
    "def radial_averaging_series(power2D, mc, min_bin=0.001, max_bin=1, bin_width=0.001):\n",
    "    \"\"\"\n",
    "    Radially average the power spectrum to obtain values. Notably the natural freqeuncy unit\n",
    "    of this function is A^-1.\n",
    "\n",
    "    Args:\n",
    "        power2D (numpy.array((M,N,N))): Power spectrum\n",
    "        mc (_type_): Membrane curvature object with metadata\n",
    "        min_bin (float, optional): Minimum bin value. Defaults to 0.001.\n",
    "        max_bin (int, optional): Maximum bin value. Defaults to 1.\n",
    "        bin_width (float, optional): Bin width. Defaults to 0.001.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Binned power spectra\n",
    "    \"\"\"\n",
    "\n",
    "    if not len(power2D.shape) == 3:\n",
    "        raise RuntimeError(\"Expected time series of 2D power\")\n",
    "\n",
    "    x, y = np.meshgrid(mc[\"qx\"], mc[\"qy\"])  # A^-1\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    bins = np.arange(min_bin, max_bin, bin_width)\n",
    "\n",
    "    digitized = np.digitize(r, bins)\n",
    "    bc = np.array(\n",
    "        [\n",
    "            r[digitized == i].mean() if np.count_nonzero(digitized == i) else np.NAN\n",
    "            for i in range(1, len(bins))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    first_iter = True\n",
    "\n",
    "    spectra = None\n",
    "\n",
    "    for i, frame in tqdm(enumerate(power2D), total=len(power2D)):\n",
    "        bm = np.array(\n",
    "            [\n",
    "                frame[digitized == i].mean()\n",
    "                if np.count_nonzero(digitized == i)\n",
    "                else np.NAN\n",
    "                for i in range(1, len(bins))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if i == 0:\n",
    "            bin_centers = bc[np.isfinite(bm)]\n",
    "            bin_means = bm[np.isfinite(bm)]\n",
    "            spectra = np.zeros((power2D.shape[0], len(bin_means)))\n",
    "            spectra[i] = bin_means\n",
    "        else:\n",
    "            spectra[i] = bm[np.isfinite(bm)]\n",
    "    return (bin_centers, spectra)\n",
    "\n",
    "\n",
    "def radial_averaging_nm(power2D, mc, min_bin=0.1, max_bin=10, bin_width=0.1):\n",
    "    x, y = np.meshgrid(mc.qx * 10, mc.qy * 10)  # convert to nm^-1\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    bins = np.arange(min_bin, max_bin, bin_width)\n",
    "\n",
    "    digitized = np.digitize(r, bins)\n",
    "    bc = np.array(\n",
    "        [\n",
    "            r[digitized == i].mean() if np.count_nonzero(digitized == i) else np.NAN\n",
    "            for i in range(1, len(bins))\n",
    "        ]\n",
    "    )\n",
    "    bm = np.array(\n",
    "        [\n",
    "            power2D[digitized == i].mean()\n",
    "            if np.count_nonzero(digitized == i)\n",
    "            else np.NAN\n",
    "            for i in range(1, len(bins))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    bin_centers = bc[np.isfinite(bm)]\n",
    "    bin_means = bm[np.isfinite(bm)]\n",
    "\n",
    "    return np.column_stack((bin_centers, bin_means, bin_centers**4 * bin_means))\n",
    "\n",
    "\n",
    "def count_residues(u):\n",
    "    count_dict = {}\n",
    "    for residue in u.residues:\n",
    "        if residue.resname not in count_dict:\n",
    "            count_dict[residue.resname] = 1\n",
    "        else:\n",
    "            count_dict[residue.resname] += 1\n",
    "    return count_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8363048-08a9-491b-ab9f-9cdf135bffbf",
   "metadata": {},
   "source": [
    "### Load data from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(util.analysis_path / \"mc_noobject.pickle\", \"rb\") as handle:\n",
    "    mc = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9fdb9-75f6-4c1a-8f58-6c099ac6df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD MEMBRANE CURVATURE OBJECTS\n",
    "# mc = {}\n",
    "# for sim in util.simulations:\n",
    "#     with open(util.analysis_path / f\"{sim}/membrane_curvature.pickle\", \"rb\") as handle:\n",
    "#         mc[sim] = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fd640-bb0d-4e99-aedc-57bef62e21ea",
   "metadata": {},
   "source": [
    "### System information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d375d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466d3571-37e6-4cb0-b63d-f51ab6ffac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5404\n",
      "System 1: CDL1: 0.12; DOPG: 0.00; POPG: 0.00; DOPE: 0.27; POPE: 0.03; DOPC: 0.46; POPC: 0.12; \n",
      "2 5406\n",
      "System 2: CDL1: 0.12; DOPG: 0.00; POPG: 0.00; DOPE: 0.29; POPE: 0.08; DOPC: 0.25; POPC: 0.26; \n",
      "3 5402\n",
      "System 3: CDL1: 0.12; DOPG: 0.00; POPG: 0.00; DOPE: 0.18; POPE: 0.14; DOPC: 0.22; POPC: 0.34; \n",
      "4 5404\n",
      "System 4: CDL1: 0.00; DOPG: 0.05; POPG: 0.06; DOPE: 0.22; POPE: 0.02; DOPC: 0.55; POPC: 0.10; \n",
      "5 5404\n",
      "System 5: CDL1: 0.00; DOPG: 0.02; POPG: 0.12; DOPE: 0.25; POPE: 0.07; DOPC: 0.34; POPC: 0.20; \n",
      "6 5402\n",
      "System 6: CDL1: 0.00; DOPG: 0.02; POPG: 0.12; DOPE: 0.18; POPE: 0.14; DOPC: 0.20; POPC: 0.34; \n",
      "7 5408\n",
      "System 7: CDL1: 1.00; DOPG: 0.00; POPG: 0.00; DOPE: 0.00; POPE: 0.00; DOPC: 0.00; POPC: 0.00; \n",
      "8 5406\n",
      "System 8: CDL1: 0.20; DOPG: 0.00; POPG: 0.00; DOPE: 0.00; POPE: 0.30; DOPC: 0.00; POPC: 0.50; \n",
      "9 5406\n",
      "System 9: CDL1: 0.20; DOPG: 0.00; POPG: 0.00; DOPE: 0.30; POPE: 0.00; DOPC: 0.50; POPC: 0.00; \n",
      "10 5406\n",
      "System 10: CDL1: 0.00; DOPG: 0.20; POPG: 0.00; DOPE: 0.00; POPE: 0.30; DOPC: 0.00; POPC: 0.50; \n",
      "11 5406\n",
      "System 11: CDL1: 0.00; DOPG: 0.20; POPG: 0.00; DOPE: 0.30; POPE: 0.00; DOPC: 0.50; POPC: 0.00; \n"
     ]
    }
   ],
   "source": [
    "def get_compositions(sim):\n",
    "    top = util.analysis_path / sim / \"system.top\"\n",
    "    gro = util.analysis_path / sim / \"membrane_only.gro\"\n",
    "\n",
    "    u = MDAnalysis.Universe(top, gro, topology_format=\"ITP\")\n",
    "    raw_composition = count_residues(u)\n",
    "\n",
    "    total_lipids = 0\n",
    "    for lipid in util.lipid_names:\n",
    "        if lipid in raw_composition:\n",
    "            total_lipids += raw_composition[lipid]\n",
    "\n",
    "    normed_composition = {}\n",
    "    s = \"\"\n",
    "    for lipid in util.lipid_names:\n",
    "        if lipid in raw_composition:\n",
    "            s += f\"{lipid}: {raw_composition[lipid]/total_lipids:0.2f}; \"\n",
    "            normed_composition[lipid] = raw_composition[lipid] / total_lipids\n",
    "        else:\n",
    "            s += f\"{lipid}: {0:0.2f}; \"\n",
    "            normed_composition[lipid] = 0\n",
    "    print(sim, total_lipids)    \n",
    "    return sim, raw_composition, normed_composition, s\n",
    "\n",
    "\n",
    "result = map(get_compositions, util.simulations)\n",
    "\n",
    "compositions = {}\n",
    "for sim, raw, normed, s in result:\n",
    "    print(f\"System {sim}: {s}\")\n",
    "    compositions[sim, \"raw_composition\"] = raw\n",
    "    compositions[sim, \"normed_composition\"] = normed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f4f313",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The topology and GRO trajectory files don't have the same number of atoms!\nTopology number of atoms 74544\nTrajectory: /Users/ctlee/Downloads/mito_lipidomics/analysis/3/production5.gro Number of atoms 340213",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(get_compositions(\u001b[39m\"\u001b[39;49m\u001b[39m3\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn [6], line 5\u001b[0m, in \u001b[0;36mget_compositions\u001b[0;34m(sim)\u001b[0m\n\u001b[1;32m      2\u001b[0m top \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39manalysis_path \u001b[39m/\u001b[39m sim \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msystem.top\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m gro \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39manalysis_path \u001b[39m/\u001b[39m sim \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mproduction5.gro\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m u \u001b[39m=\u001b[39m MDAnalysis\u001b[39m.\u001b[39;49mUniverse(top, gro, topology_format\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mITP\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m raw_composition \u001b[39m=\u001b[39m count_residues(u)\n\u001b[1;32m      8\u001b[0m total_lipids \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:365\u001b[0m, in \u001b[0;36mUniverse.__init__\u001b[0;34m(self, topology, all_coordinates, format, topology_format, transformations, guess_bonds, vdwradii, in_memory, in_memory_step, *coordinates, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m coordinates \u001b[39m=\u001b[39m _resolve_coordinates(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename, \u001b[39m*\u001b[39mcoordinates,\n\u001b[1;32m    361\u001b[0m                                    \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m,\n\u001b[1;32m    362\u001b[0m                                    all_coordinates\u001b[39m=\u001b[39mall_coordinates)\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m coordinates:\n\u001b[0;32m--> 365\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_new(coordinates, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m, in_memory\u001b[39m=\u001b[39;49min_memory,\n\u001b[1;32m    366\u001b[0m                 in_memory_step\u001b[39m=\u001b[39;49min_memory_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    368\u001b[0m \u001b[39mif\u001b[39;00m transformations:\n\u001b[1;32m    369\u001b[0m     \u001b[39mif\u001b[39;00m callable(transformations):\n",
      "File \u001b[0;32m~/mambaforge/envs/mda/lib/python3.10/site-packages/MDAnalysis/core/universe.py:569\u001b[0m, in \u001b[0;36mUniverse.load_new\u001b[0;34m(self, filename, format, in_memory, in_memory_step, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory \u001b[39m=\u001b[39m reader(filename, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory\u001b[39m.\u001b[39mn_atoms \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39matoms):\n\u001b[0;32m--> 569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe topology and \u001b[39m\u001b[39m{form}\u001b[39;00m\u001b[39m trajectory files don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m have the same number of atoms!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mTopology number of atoms \u001b[39m\u001b[39m{top_n_atoms}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mTrajectory: \u001b[39m\u001b[39m{fname}\u001b[39;00m\u001b[39m Number of atoms \u001b[39m\u001b[39m{trj_n_atoms}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    573\u001b[0m                          form\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory\u001b[39m.\u001b[39mformat,\n\u001b[1;32m    574\u001b[0m                          top_n_atoms\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39matoms),\n\u001b[1;32m    575\u001b[0m                          fname\u001b[39m=\u001b[39mfilename,\n\u001b[1;32m    576\u001b[0m                          trj_n_atoms\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory\u001b[39m.\u001b[39mn_atoms))\n\u001b[1;32m    578\u001b[0m \u001b[39mif\u001b[39;00m in_memory:\n\u001b[1;32m    579\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransfer_to_memory(step\u001b[39m=\u001b[39min_memory_step, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: The topology and GRO trajectory files don't have the same number of atoms!\nTopology number of atoms 74544\nTrajectory: /Users/ctlee/Downloads/mito_lipidomics/analysis/3/production5.gro Number of atoms 340213"
     ]
    }
   ],
   "source": [
    "print(get_compositions(\"3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed2ec8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(compositions[sim, \u001b[39m\"\u001b[39m\u001b[39mraw_composition\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sim' is not defined"
     ]
    }
   ],
   "source": [
    "print(compositions[sim, \"raw_composition\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80a6f0",
   "metadata": {},
   "source": [
    "## Defining Statistical Inefficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76677f3f",
   "metadata": {},
   "source": [
    "Given a sequence of measurements $A_i$ sampled from a timeseries, we must investigate the degree of correlation to estimate the sampling error. We estimate the error by quantifying the statistical inefficiency.\n",
    "\n",
    "We start by computing the block averaged values, $\\langle A\\rangle_b$ over a range of block lengths $t_b$,\n",
    "$$\\langle A\\rangle_b = \\frac{1}{t_b} \\sum_{i=1}^{t_b} A_i.$$\n",
    "\n",
    "As the number of steps increases, we expect that the block averages become uncorrelated. The variance of block averages $\\sigma^2(\\langle A\\rangle_b)$,\n",
    "$$\\sigma^2(\\langle A\\rangle_b) = \\frac{1}{n_b}\\sum_{b=1}^{n_b} (\\langle A\\rangle_b - \\langle A_i\\rangle)^2,$$\n",
    "becomes inversely proportional to $t_b$ as the block averages become uncorrelated.\n",
    "\n",
    "At the uncorrelated limit, the statistical inefficiency is given by,\n",
    "$$ s = \\lim_{t_b\\rightarrow \\infty} \\frac{t_b \\sigma^2(\\langle A\\rangle_b)}{\\sigma^2(A)}.$$\n",
    "\n",
    "The 'true' standard deviation of the average value is then related to the traditional standard deviation by,\n",
    "$$\\sigma_{\\langle A\\rangle} \\approx \\sigma \\sqrt{\\frac{s}{M}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c8c72",
   "metadata": {},
   "source": [
    "## Setting up parametric error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc5c57",
   "metadata": {},
   "source": [
    "Given a sequence of evenly space measurements ${X_1, X_2,\\ldots, X_T}$ along a trajectory, the sample mean $m_X$ and sample variance $s^2_X$ is given by\n",
    "\n",
    "$$m_X = \\frac{1}{T} \\sum_{i=1}^{T}X_i,$$\n",
    "$$s^2_X = \\frac{1}{T-1}\\sum_{i=1}^{T}(X_i - m_X)^2.$$\n",
    "\n",
    "The error of the mean can be estimated using $\\delta X = s_X / \\sqrt{T}$ if the data are uncorrelated. Since the measurements are sampled from a dynamical trajectory, there is no guarantee that there is no correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efb48a-b085-46e4-9f1d-9b76c46cdbc4",
   "metadata": {},
   "source": [
    "## Kc Bending Modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab73780",
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_low_q = 0.4 / 10  # A^-1\n",
    "\n",
    "def fit_kc_from_power(\n",
    "    power2D, mc=None, threshold=0.03, min_bin=0.001, max_bin=1, bin_width=0.001\n",
    "):\n",
    "    spectra = radial_averaging(\n",
    "        power2D, mc, min_bin=min_bin, max_bin=max_bin, bin_width=bin_width\n",
    "    )\n",
    "    mask = spectra[:, 0] < threshold\n",
    "    spectra_cut = spectra[mask, :]\n",
    "\n",
    "    return 1.0 / spectra_cut[:, 2].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    gro = util.analysis_path / f\"{sim}/po4_only.gro\"\n",
    "    traj = util.analysis_path / f\"{sim}/po4_all.xtc\"\n",
    "\n",
    "    u = MDAnalysis.Universe(gro, str(traj), refresh_offsets=True)\n",
    "    dims = [u.dimensions[0] for ts in u.trajectory]\n",
    "    print(\n",
    "        f\"{sim}: mean {np.mean(dims)}, min {np.min(dims)}, max {np.max(dims)} Angstroms\"\n",
    "    )\n",
    "    areas[sim] = np.mean(dims) ** 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0434011",
   "metadata": {},
   "source": [
    "### Block analysis of Fourier modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override and recompute even if spectra pickle exists\n",
    "spectra_compute_override = False\n",
    "\n",
    "spectra_fd = util.analysis_path / \"spectra.pickle\"\n",
    "if spectra_fd.exists() and not spectra_compute_override:\n",
    "    # LOAD SPECTRA PICKLE\n",
    "    with open(spectra_fd, \"rb\") as handle:\n",
    "        spectra = pickle.load(handle)\n",
    "    print(\"Loaded spectra from cache!\")\n",
    "else:\n",
    "    def compute_spectra(sim):\n",
    "        return sim, radial_averaging_series(\n",
    "            mc[sim][\"height_power_spectrum\"],\n",
    "            mc[sim],\n",
    "            min_bin=0.001,\n",
    "            max_bin=1,\n",
    "            bin_width=0.001,\n",
    "        )\n",
    "\n",
    "    spectra = dict(map(compute_spectra, util.simulations))\n",
    "\n",
    "    # WRITE SPECTRA TO PICKLE\n",
    "    with open(spectra_fd, \"wb\") as handle:\n",
    "        pickle.dump(spectra, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# POPULATE q^4*h_q\n",
    "qfour_spectra = {}\n",
    "for sim in util.simulations:\n",
    "    qfour_spectra[sim] = np.power(spectra[sim][0], 4) * spectra[sim][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12798a11",
   "metadata": {},
   "source": [
    "#### Timeseries of wavenumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153dda2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_figs = False\n",
    "curr_fig_path = Path(\"Figures/power_timeseries\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "## PLOT HEIGHT POWER TIMESERIES\n",
    "for sim in util.simulations:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "\n",
    "    for i in range(0, 4):\n",
    "        ax.plot(\n",
    "            range(len(spectra[sim][1][:, i])),\n",
    "            spectra[sim][1][:, i],\n",
    "            linewidth=NORMAL_LINE,\n",
    "            label=f\"q{i}\",\n",
    "        )\n",
    "        \n",
    "        # plot q^4*h_q instead\n",
    "        # ax.plot(\n",
    "        #     range(len(spectra[sim][1][:, i])),\n",
    "        #     np.power(spectra[sim][0][i],4)*spectra[sim][1][:, i],\n",
    "        #     linewidth=NORMAL_LINE,\n",
    "        #     label=f\"q{i}\",\n",
    "        # )\n",
    "\n",
    "    ax.set_xlabel(r\"Frame\")\n",
    "    ax.set_ylabel(r\"Power Spectrum $\\langle|h_q|\\rangle^2$ (nm$^{-4}$)\")\n",
    "    ax.set_title(f\"Sys{sim}:{util.system_names[sim]}\")\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "    # # Shrink current axis by 20%\n",
    "    # box = ax.get_position()\n",
    "    # ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # # Put a legend to the right of the current axis\n",
    "    # ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(curr_fig_path/f\"{sim}_power_timeseries.png\", format=\"png\")\n",
    "\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "        \n",
    "    fig.clear()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f5e23",
   "metadata": {},
   "source": [
    "#### Statistical inefficiency of Fourier amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd271d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = False\n",
    "curr_fig_path = Path(\"Figures/amplitude_si\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "## COMPUTE STATISTICAL INEFFICIENCY OF WAVE NUMBERS UP TO max_q\n",
    "max_q = 4\n",
    "discards = np.arange(0, 60, 10)\n",
    "blocks = np.arange(1, 2**8 + 1, 1)\n",
    "\n",
    "cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "\n",
    "for sim in util.simulations:\n",
    "    for q in range(0, max_q):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "        c = cmap(np.linspace(0, 1, len(discards)))\n",
    "\n",
    "        _, _, si = util.statistical_inefficiency(\n",
    "            qfour_spectra[sim][:, q], blocks, discards\n",
    "        )\n",
    "\n",
    "        for d, discard in enumerate(discards):\n",
    "            ax.plot(\n",
    "                blocks,\n",
    "                si[d],\n",
    "                color=c[d],\n",
    "                linewidth=NORMAL_LINE,\n",
    "                label=f\"{100-discard}%\",\n",
    "            )\n",
    "\n",
    "        ax.set_xlabel(r\"Blocks\")\n",
    "        ax.set_ylabel(r\"Statistical inefficiency\")\n",
    "        ax.set_title(f\"Sys {sim}: {util.system_names[sim]}, q4Hq{q}\")\n",
    "        ax.legend(loc=\"upper left\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # # Shrink current axis by 20%\n",
    "        # box = ax.get_position()\n",
    "        # ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "        # # Put a legend to the right of the current axis\n",
    "        # ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        fig.savefig(curr_fig_path/f\"{sim}_q4Hq{q}.png\", format=\"png\")\n",
    "\n",
    "        if show_figs:\n",
    "            plt.show()\n",
    "        fig.clear()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c5122",
   "metadata": {},
   "source": [
    "Conclude that the wavenumbers appear to equilibrate rapidly and we can keep the majority of the trajectory. Henceforth we will discard 10% from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d23fbf",
   "metadata": {},
   "source": [
    "#### Block averaging of amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b76b6",
   "metadata": {},
   "source": [
    "The correlation time of the squared standard error of the mean should follow such a trend:\n",
    "$$\\frac{\\delta X^2_b}{\\delta X^2_1} = \\frac{1+c_t}{1-c_t} - \\frac{2*c_t}{b} * \\frac{1-c^b_t}{(1-c_t)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe38e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_time_sqrt(b, tau):\n",
    "    ct = np.exp(-1 / tau)\n",
    "    cb = np.exp(-b / tau)\n",
    "    return np.sqrt((1 + ct) / (1 - ct) - (2 * ct) / b * (1 - cb) / np.power(1 - ct, 2))\n",
    "\n",
    "def correlation_time(b, tau):\n",
    "    ct = np.exp(-1 / tau)\n",
    "    cb = np.exp(-b / tau)\n",
    "    return (1 + ct) / (1 - ct) - (2 * ct) / b * (1 - cb) / np.power(1 - ct, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard first X% for all trajectories\n",
    "discard = 10\n",
    "max_q_dict = {}\n",
    "blocks = np.arange(1, 2**9 + 1, 1)\n",
    "\n",
    "block_var = {}\n",
    "lp_block_sem = {}\n",
    "block_mean = {}\n",
    "for sim in util.simulations:\n",
    "    max_q = sum(spectra[sim][0] < kc_low_q)\n",
    "\n",
    "    max_q_dict[sim]  = max_q\n",
    "\n",
    "    block_mean[sim] = np.zeros((max_q, len(blocks)))\n",
    "    block_var[sim] = np.zeros((max_q, len(blocks)))\n",
    "    lp_block_sem[sim] = np.zeros((max_q, len(blocks)))\n",
    "\n",
    "    low_q_data = qfour_spectra[sim][:, 0:max_q]\n",
    "    # low_q_data = spectra[sim][1][:, 0:max_q]\n",
    "    \n",
    "    _, remainder = np.split(low_q_data, [int(discard / 100 * len(low_q_data))])\n",
    "\n",
    "    block_mean[sim] = util.nd_block_average(remainder, axis=0, func=np.mean, blocks=blocks)\n",
    "    block_var[sim] = util.nd_block_average(remainder, axis=0, func=partial(np.var, ddof=1), blocks=blocks)\n",
    "    lp_block_sem[sim] = util.nd_block_average(remainder, axis=0, func=partial(stats.sem, ddof=1), blocks=blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = False\n",
    "curr_fig_path = Path(\"Figures/kc_block_error\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "corrected_mean_sem = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "\n",
    "    corrected_mean_sem[sim] = np.empty((2, max_q_dict[sim]))\n",
    "\n",
    "    for q in range(0, max_q_dict[sim]):\n",
    "        # Mean with block size 1\n",
    "        corrected_mean_sem[sim][0, q] = block_mean[sim][q][0] \n",
    "        blocked_sem = lp_block_sem[sim][q]\n",
    "        popt, pcov = curve_fit(\n",
    "            correlation_time_sqrt, blocks, blocked_sem / blocked_sem[0]\n",
    "        )\n",
    "        corrected_mean_sem[sim][1, q] = blocked_sem[0]* np.sqrt(2*popt[0])\n",
    "        \n",
    "        ax.plot(\n",
    "            np.log2(blocks),\n",
    "            blocked_sem / blocked_sem[0],\n",
    "            linewidth=NORMAL_LINE,\n",
    "            label=f\"q{q}\",\n",
    "            color=sns.color_palette(\"colorblind\")[q],\n",
    "            linestyle=\":\",\n",
    "        )\n",
    "\n",
    "        ax.plot(\n",
    "            np.log2(blocks),\n",
    "            [correlation_time_sqrt(block, popt) for block in blocks],\n",
    "            linewidth=NORMAL_LINE,\n",
    "            color=sns.color_palette(\"colorblind\")[q],\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(r\"$log_2$(block)\")\n",
    "    ax.set_ylabel(r\"$\\delta X_b/\\delta X_1$\")\n",
    "    ax.set_title(f\"Sys{sim}:{util.system_names[sim]}\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(curr_fig_path/f\"{sim}_block_error.png\", format=\"png\")\n",
    "\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9203f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(4):\n",
    "#     print(f\"q^4h_q ({i}) = {corrected_mean_sem[\"4\"][0]} +- {corrected_mean_sem[\"4\"][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Discard first X% for all trajectories\n",
    "# discard = 10\n",
    "# max_q = 4\n",
    "# blocks = np.arange(1, 2**9 + 1, 1)\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     low_q_data = qfour_spectra[sim][:, 0:max_q]\n",
    "#     # low_q_data = spectra[sim][1][:, 0:max_q]\n",
    "    \n",
    "#     _, remainder = np.split(low_q_data, [int(discard / 100 * len(low_q_data))])\n",
    "\n",
    "#     hq_mean = np.mean(remainder, axis=0)\n",
    "\n",
    "#     util.nd_block_average(remainder, axis=0, func=np.mean, blocks=blocks)\n",
    "#     block_sem = util.nd_block_average(remainder, axis=0, func=partial(stats.sem, ddof=1), blocks=blocks)\n",
    "\n",
    "#     corrected_hq_sem = np.empty((max_q))\n",
    "\n",
    "#     for q in range(max_q):\n",
    "#         blocked_sem = block_sem[q]\n",
    "#         popt, pcov = curve_fit(\n",
    "#             correlation_time_sqrt, blocks, block_sem[q] / block_sem[q][0]\n",
    "#         )\n",
    "#         corrected_hq_sem[q] = block_sem[q][0]* np.sqrt(2*popt[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e216b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "c = cmap(np.linspace(0, 1, len(util.simulations)))\n",
    "\n",
    "kc_mean_std = np.empty((len(util.simulations), 2))\n",
    "\n",
    "# Bootstrap values\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "for i, sim in enumerate(util.simulations):\n",
    "    f_rvs = []\n",
    "\n",
    "    # Construct random Gaussian processe for each wavenumber\n",
    "    for q in range(corrected_mean_sem[sim].shape[1]):\n",
    "        # print(corrected_mean_sem[sim][0, i], corrected_mean_sem[sim][1][i])\n",
    "        r = stats.norm(\n",
    "            loc=corrected_mean_sem[sim][0, q], scale=corrected_mean_sem[sim][1][q]\n",
    "        )\n",
    "        f_rvs.append(r.rvs)\n",
    "    # Run parametric bootstrap with random proceses\n",
    "    boot = util.parametric_bootstrap(f_rvs, n_samples=50000)\n",
    "    \n",
    "    # Fit kcs to bootstrap samples\n",
    "    kcs = 1.0 / np.mean(boot, axis=0)\n",
    "\n",
    "    # Plot distribution of kcs\n",
    "    ax.hist(\n",
    "        kcs,\n",
    "        bins=50,\n",
    "        density=True,\n",
    "        color=c[i],\n",
    "        label=f\"{sim} {util.system_names[sim]}\",\n",
    "    )\n",
    "\n",
    "    kc_mean_std[i] = [np.mean(kcs), np.std(kcs)]\n",
    "\n",
    "    print(\n",
    "        sim, kc_mean_std[i]\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(r\"$K_c$ ($k_BT$)\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "fig.savefig(curr_fig_path / f\"kc_distributions.png\", format=\"png\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = False\n",
    "curr_fig_path = Path(\"Figures/height_spectra_kc\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Discard first X% for all trajectories\n",
    "discard = 10\n",
    "max_q = 100\n",
    "\n",
    "for i, sim in enumerate(util.simulations):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "    low_q_data = qfour_spectra[sim][:, 0:max_q]\n",
    "    # low_q_data = spectra[sim][1][:, 0:max_q]\n",
    "\n",
    "    _, remainder = np.split(low_q_data, [int(discard / 100 * len(low_q_data))])\n",
    "\n",
    "    # Convert to nm^-1\n",
    "    q = spectra[sim][0][0:max_q] * 10\n",
    "    mask = q < kc_low_q * 10\n",
    "\n",
    "    # q^4*hq\n",
    "    hq_mean = np.mean(remainder, axis=0)\n",
    "    hq_std = np.std(remainder, axis=0)\n",
    "\n",
    "\n",
    "    ax.errorbar(q[mask], hq_mean[mask], yerr=hq_std[mask], fmt=\".\", markersize=3, elinewidth=THIN_LINE, ecolor=\"lightgray\")\n",
    "\n",
    "    ax.errorbar(q[~mask], hq_mean[~mask], yerr=hq_std[~mask], color=\"dimgray\", fmt=\".\", markersize=3, elinewidth=THIN_LINE, ecolor=\"lightgray\")\n",
    "\n",
    "    ax.axhline(1/kc_mean_std[i][0], color=\"r\")\n",
    "    # ax.axvline(kc_low_q, color=\"k\", linewidth=0.5, linestyle=\":\")\n",
    "\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.7,\n",
    "        f\"$K_c$ = {kc_mean_std[i][0]:.1f} $\\pm$ {kc_mean_std[i][1]:.1f} $k_BT$\",\n",
    "        color=\"r\",\n",
    "        transform=ax.transAxes\n",
    "    )\n",
    "\n",
    "    # ax.set_xlim(5e-2, 5)\n",
    "    ax.set_ylim(0.0, 0.45)\n",
    "    ax.set_xscale(\"log\")\n",
    "\n",
    "    ax.set_ylabel(r\"$q^4 \\times \\mathrm{intensity}$ (nm$^2$)\")\n",
    "    ax.set_xlabel(r\"$q$ (nm$^{-1}$)\")\n",
    "\n",
    "    ax.set_title(f\"System {sim}: {util.system_names[sim]}\")\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "\n",
    "    fig.savefig(curr_fig_path/f\"{sim}_height_spectra_kc.png\", format=\"png\")\n",
    "\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "        \n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da880ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "c1 = mpl.cm.get_cmap(\"Purples\")(np.linspace(0.2, 0.8, 3))\n",
    "c2 = mpl.cm.get_cmap(\"Reds\")(np.linspace(0.2, 0.8, 3))\n",
    "\n",
    "c3 = np.array([0.2, 0.2, 0.2, 1]).reshape(1, -1)\n",
    "\n",
    "c4 = mpl.cm.get_cmap(\"Blues\")(np.linspace(0.8, 0.2, 2))\n",
    "c5 = mpl.cm.get_cmap(\"Oranges\")(np.linspace(0.8, 0.2, 2))\n",
    "\n",
    "colors = np.vstack((c1, c2, c3, c4, c5))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "ax.bar(\n",
    "    range(kc_mean_std.shape[0]), kc_mean_std[:, 0], color=colors, yerr=kc_mean_std[:, 1]\n",
    ")\n",
    "\n",
    "ax.set_ylabel(r\"$K_c$ ($k_BT$)\")\n",
    "ax.set_xlabel(r\"System\")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticks(),\n",
    ")\n",
    "\n",
    "x_ticks_labels = [f\"{sim}\" for sim in util.simulations]\n",
    "\n",
    "# Set number of ticks for x-axis\n",
    "ax.set_xticks(range(11))\n",
    "# Set ticks labels for x-axis\n",
    "ax.set_xticklabels(x_ticks_labels)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(curr_fig_path / f\"estimated_kcs.png\", format=\"png\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show()\n",
    "\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057bb8f-63c7-4c50-8e3b-bac49147458d",
   "metadata": {},
   "source": [
    "### Statistical Inefficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7189ae3-2232-4576-be6c-1cdcdf9705bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO REGENERATE DATA\n",
    "\n",
    "# _s = 10  # Min block\n",
    "\n",
    "# discards = np.arange(0, 100, 10)  # Percent of data to discard from end\n",
    "# blocks = np.arange(1, 101, 1, dtype=int)\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     print(\"Processing system:\", sim)\n",
    "\n",
    "#     # Populate some basic information\n",
    "#     frame_dt = mc[sim].times[1] - mc[sim].times[0]  # picoseconds\n",
    "\n",
    "#     print(frame_dt)\n",
    "#     _b = 0\n",
    "#     _e = len(mc[sim].frames)\n",
    "#     n_frames = len(range(_b, _e + 1, _s))\n",
    "#     shape = mc[sim].P.shape\n",
    "\n",
    "#     # Times from mdanalysis are unreliable due to restarts\n",
    "#     # times = mc[sys].times[np.arange(0, _e, _s, dtype=int)]\n",
    "#     times = np.arange(0, _e, _s, dtype=int) * frame_dt  # picoseconds\n",
    "\n",
    "#     # Split into chunks and compute kcs\n",
    "#     split_indices = np.arange(_s, _e, _s, dtype=int)\n",
    "#     powers = np.fromiter(\n",
    "#         map(\n",
    "#             partial(np.mean, axis=0),\n",
    "#             np.split(mc[sim].results[\"height_power_spectrum\"], split_indices),\n",
    "#         ),\n",
    "#         dtype=np.dtype((np.double, (shape))),\n",
    "#     )\n",
    "#     kcs = np.fromiter(\n",
    "#         map(partial(fit_kc_from_power, threshold=kc_low_q, mc=mc[sim]), powers),\n",
    "#         dtype=np.double,\n",
    "#     )\n",
    "\n",
    "#     # Plot Kc evaluated over 5ns (0.5 * _s) blocks\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "#     # fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "\n",
    "#     ax.plot(times * 1e-6, kcs)  # Convert to microseconds\n",
    "#     # ax2.plot(times * 1e-6, kcs)  # Convert to microseconds\n",
    "\n",
    "#     # ax1.set_ylim(50, 100)\n",
    "#     # ax2.set_ylim(0, 30)\n",
    "\n",
    "#     # # hide the spines between ax and ax2\n",
    "#     # ax1.spines.bottom.set_visible(False)\n",
    "#     # ax2.spines.top.set_visible(False)\n",
    "#     # ax1.xaxis.tick_top()\n",
    "#     # ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "#     # ax2.xaxis.tick_bottom()\n",
    "\n",
    "#     # # Now, let's turn towards the cut-out slanted lines.\n",
    "#     # # We create line objects in axes coordinates, in which (0,0), (0,1),\n",
    "#     # # (1,0), and (1,1) are the four corners of the axes.\n",
    "#     # # The slanted lines themselves are markers at those locations, such that the\n",
    "#     # # lines keep their angle and position, independent of the axes size or scale\n",
    "#     # # Finally, we need to disable clipping.\n",
    "\n",
    "#     # d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "#     # kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "#     #             linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "#     # ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "#     # ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "#     ax.set_ylabel(r\"$K_c$ ($k_b$T)\")\n",
    "#     ax.set_xlabel(r\"Time (μs)\")\n",
    "\n",
    "#     ax.set_title(f\"System {sim}: {util.system_names[sim]}\")\n",
    "\n",
    "#     # fig.tight_layout()\n",
    "#     save_fig(fig, f\"Figures/{sim}_kc_5nsblock\")\n",
    "\n",
    "#     ## Perform block analysis\n",
    "#     kc_mean = kcs.mean()\n",
    "\n",
    "#     SI = {}\n",
    "#     SI[\"discards\"] = discards\n",
    "#     SI[\"blocks\"] = blocks * frame_dt * _s  # picoseconds\n",
    "\n",
    "#     for discard in discards:\n",
    "#         _, r = np.split(kcs, [int(discard / 100 * n_frames)])\n",
    "#         kc_mean = r.mean()\n",
    "\n",
    "#         SI[(discard, \"sigma\")] = np.zeros(len(blocks))\n",
    "#         SI[(discard, \"mean\")] = np.zeros(len(blocks))\n",
    "\n",
    "#         for i, block in enumerate(blocks):\n",
    "#             n = np.floor(len(r) / block)\n",
    "\n",
    "#             split_indices = np.arange(block, len(r), block, dtype=int)\n",
    "#             block_kcs = np.fromiter(\n",
    "#                 map(np.mean, np.split(r, split_indices)), dtype=np.double\n",
    "#             )\n",
    "\n",
    "#             # Truncate number of blocks if not evenly divisible\n",
    "#             if len(r) % block:\n",
    "#                 block_kcs = block_kcs[:-1]\n",
    "\n",
    "#             SI[(discard, \"sigma\")][i] = np.sum((block_kcs - kc_mean) ** 2) / n\n",
    "#             SI[(discard, \"mean\")][i] = np.mean(block_kcs)\n",
    "\n",
    "#     with open(util.analysis_path / f\"{sim}/SI.pickle\", \"wb\") as handle:\n",
    "#         pickle.dump(SI, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load bending modulus statistical inefficiency\n",
    "# SI_kc = {}\n",
    "# for sim in util.simulations:\n",
    "#     with open(util.analysis_path / sim / \"SI.pickle\", \"rb\") as handle:\n",
    "#         SI_kc[sim] = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b13e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Foreshadow percent discard, statistical inefficiency for all systems\n",
    "# si_kc_system = {\n",
    "#     \"1\": (50, 25),\n",
    "#     \"2\": (50, 25),\n",
    "#     \"3\": (50, 25),\n",
    "#     \"4\": (50, 13),\n",
    "#     \"5\": (20, 15),\n",
    "#     \"6\": (20, 15),\n",
    "#     \"7\": (50, 28),\n",
    "#     \"8\": (50, 25),\n",
    "#     \"9\": (50, 25),\n",
    "#     \"10\": (50, 25),\n",
    "#     \"11\": (50, 25),\n",
    "# }\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     print(f\"System {sim} ({util.system_names[sim]}):\")\n",
    "#     print(f\"  statistical inefficiency: {si_kc_system[sim][1]} ns\")\n",
    "#     print(f\"                   discard: {si_kc_system[sim][0]}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     d = SI_kc[sim]\n",
    "#     discards = d[\"discards\"]\n",
    "#     c = cmap(np.linspace(0, 1, len(discards)))\n",
    "\n",
    "#     times = d[\"blocks\"] * 1e-3  # picoseconds -> nanoseconds\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "#     for i, discard in enumerate(discards):\n",
    "#         sigma = d[(discard, \"sigma\")]\n",
    "#         si = times * (sigma / sigma[0])\n",
    "\n",
    "#         if discard == si_kc_system[sim][0]:\n",
    "#             alpha = 1\n",
    "#         else:\n",
    "#             alpha = 0.2\n",
    "#         ax.plot(\n",
    "#             times,\n",
    "#             si,\n",
    "#             color=c[i],\n",
    "#             alpha=alpha,\n",
    "#             linewidth=NORMAL_LINE,\n",
    "#             label=f\"{100-discard}%\",\n",
    "#         )\n",
    "\n",
    "#     ax.axvline(100, color=\"k\", linestyle=\"dotted\", linewidth=THINNER_LINE)\n",
    "#     ax.axhline(\n",
    "#         si_kc_system[sim][1], color=\"k\", linestyle=\"dotted\", linewidth=THINNER_LINE\n",
    "#     )\n",
    "\n",
    "#     ax.set_ylabel(r\"Statistical Inefficiency (ns)\")\n",
    "#     ax.set_xlabel(r\"Bin Width (ns)\")\n",
    "#     ax.set_title(f\"System {sim}: {util.system_names[sim]}\")\n",
    "#     # ax.legend()\n",
    "\n",
    "#     # Shrink current axis by 20%\n",
    "#     box = ax.get_position()\n",
    "#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "#     # Put a legend to the right of the current axis\n",
    "#     ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), title=\"Keep\")\n",
    "\n",
    "#     ax.set_xlim(0, 200)\n",
    "#     ax.set_ylim(0.0, 50)\n",
    "#     # plt.tight_layout()\n",
    "#     save_fig(fig, f\"Figures/{sim}_StatIneff\")\n",
    "#     plt.show()\n",
    "#     fig.clear()\n",
    "#     plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5656e65",
   "metadata": {},
   "source": [
    "### Plots of height power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _s = 10  # Min block\n",
    "# cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "\n",
    "# fig_all, ax_all = plt.subplots(1, 1, figsize=(6, 3))\n",
    "# KB_VALUES = {}\n",
    "# for sim in util.simulations:\n",
    "#     print(\"Processing system:\", sim)\n",
    "#     discard = si_kc_system[sim][0]\n",
    "#     si = si_kc_system[sim][1] * 1e3 / 500  # nanseconds -> picoseconds -> frames\n",
    "\n",
    "#     _, r = np.split(\n",
    "#         mc[sim].results.height_power_spectrum,\n",
    "#         [int(discard / 100 * len(mc[sim].results.height_power_spectrum))],\n",
    "#     )\n",
    "\n",
    "#     m = SI_kc[sim][(discard, \"mean\")][0]\n",
    "#     sigma = SI_kc[sim][(discard, \"sigma\")][0]\n",
    "\n",
    "#     KB_VALUES[sim] = m\n",
    "\n",
    "#     N = len(r)\n",
    "#     stdev = sigma * np.sqrt(si / N)\n",
    "\n",
    "#     print(m, sigma, N, si, stdev)\n",
    "\n",
    "#     c = cmap(np.linspace(0, 1, len(util.simulations)))\n",
    "\n",
    "#     height_spectra = radial_averaging(np.mean(r, axis=0), mc[sim])\n",
    "\n",
    "#     mask = height_spectra[:, 0] < kc_low_q\n",
    "#     height_spectra[:, 0] *= 10  # Convert to nm^-1\n",
    "#     height_spectra_cut = height_spectra[mask, :]\n",
    "#     height_spectra_r = height_spectra[~mask, :]\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "#     ax.scatter(height_spectra_r[:, 0], height_spectra_r[:, 2], color=\"silver\", s=8)\n",
    "#     ax.scatter(height_spectra_cut[:, 0], height_spectra_cut[:, 2], s=8)\n",
    "\n",
    "#     ax.axhline(1 / m, color=\"r\")\n",
    "#     ax.axvline(kc_low_q, color=\"k\", linewidth=0.5, linestyle=\":\")\n",
    "\n",
    "#     ax.set_xlim(5e-2, 2.5)\n",
    "#     ax.set_ylim(0.0, 0.4)\n",
    "#     ax.set_xscale(\"log\")\n",
    "\n",
    "#     ax.text(\n",
    "#         0.1,\n",
    "#         0.2,\n",
    "#         f\"$K_c$ = {m:.1f} $\\pm$ {stdev:.1f} $k_BT$\",\n",
    "#         color=\"r\",\n",
    "#     )\n",
    "\n",
    "#     ax.set_ylabel(r\"$q^4 \\times \\mathrm{intensity}$ (-)\")\n",
    "#     ax.set_xlabel(r\"$q$ (nm$^{-1}$)\")\n",
    "#     ax.set_title(f\"System {sim}: {util.system_names[sim]}\")\n",
    "#     fig.set_tight_layout(True)\n",
    "\n",
    "#     save_fig(fig, f\"Figures/{sim}_kc\")\n",
    "#     # plt.show()\n",
    "#     # fig.clear()\n",
    "#     # plt.close(fig)\n",
    "\n",
    "#     ax_all.scatter(\n",
    "#         height_spectra[:, 0],\n",
    "#         height_spectra[:, 2],\n",
    "#         color=c[int(sim) - 1],\n",
    "#         label=f\"System {sim} {util.system_names[sim]}\",\n",
    "#     )\n",
    "\n",
    "# # Shrink current axis by 20%\n",
    "# box = ax_all.get_position()\n",
    "# ax_all.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# # Put a legend to the right of the current axis\n",
    "# ax_all.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# ax_all.set_xlim(5e-2, 2.5)\n",
    "# ax_all.set_ylim(0.0, 0.4)\n",
    "# ax_all.set_xscale(\"log\")\n",
    "# ax_all.set_ylabel(r\"$q^4 \\times \\mathrm{intensity}$ (-)\")\n",
    "# ax_all.set_xlabel(r\"$q$ (nm$^{-1}$)\")\n",
    "# fig_all.set_tight_layout(True)\n",
    "# save_fig(fig_all, \"height_spectrum-all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc539b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# temp_kc = np.empty((len(util.simulations), 2))\n",
    "# for i, sim in enumerate(util.simulations):\n",
    "#     discard = si_kc_system[sim][0]\n",
    "#     si = si_kc_system[sim][1] * 1e3 / 500  # nanseconds -> picoseconds -> frames\n",
    "#     _, r = np.split(\n",
    "#         mc[sim].results.height_power_spectrum,\n",
    "#         [int(discard / 100 * len(mc[sim].results.height_power_spectrum))],\n",
    "#     )\n",
    "    \n",
    "#     m = SI_kc[sim][(discard, \"mean\")][0]\n",
    "#     sigma = SI_kc[sim][(discard, \"sigma\")][0]\n",
    "\n",
    "#     N = len(r)\n",
    "#     stdev = sigma * np.sqrt(si / N)\n",
    "\n",
    "#     temp_kc[i] = [m, stdev]\n",
    "    \n",
    "# np.savetxt(\"sheets/kb.csv\", temp_kc, delimiter=\",\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b25dc4",
   "metadata": {},
   "source": [
    "# Neighbor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "# Lipids in order in results matrix\n",
    "lipids = [\"POPC\", \"DOPC\", \"POPE\", \"DOPE\", \"CDL1\", \"POPG\", \"DOPG\"]\n",
    "lipid_dict = dict([[j, i] for i, j in enumerate(lipids)])\n",
    "leaflets = [\"upper\", \"lower\"]\n",
    "\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)\n",
    "\n",
    "\n",
    "def print_neighbor_analysis(dataset, prefix=\"\"):\n",
    "    for sim in util.simulations:\n",
    "        print(f\"System {sim}: {util.system_names[sim]}\")\n",
    "\n",
    "        raw_baseline = []\n",
    "        baseline = []\n",
    "        s = \"\"\n",
    "        for lipid in lipids:\n",
    "            if lipid in compositions[sim, \"raw_composition\"]:\n",
    "                # div by 2 to account for leaflet composition\n",
    "                raw_baseline.append(compositions[sim, \"raw_composition\"][lipid] / 2)\n",
    "            else:\n",
    "                raw_baseline.append(0)\n",
    "            s += f\"{lipid}: {compositions[sim, 'normed_composition'][lipid]:0.3f}, \"\n",
    "            baseline.append(compositions[sim, \"normed_composition\"][lipid])\n",
    "        raw_baseline = np.array(raw_baseline).reshape(-1, 1)  # COLUMN VECTOR\n",
    "        print(s)\n",
    "        # fraction of each lipid per leaflet\n",
    "        baseline = np.array(baseline)\n",
    "        # print(raw_baseline, baseline)\n",
    "\n",
    "        # Aggregate statistics from both leaflets\n",
    "        counts_per_frame = (dataset[sim][\"upper\"] + dataset[sim][\"lower\"]) / 2\n",
    "        # Keep only back half of trajectory\n",
    "        N = int(0.5 * len(counts_per_frame))\n",
    "        counts = np.mean(counts_per_frame[N:-1], axis=0)  # mean counts per frame\n",
    "\n",
    "        # Copy counts across diagonal which must be symmetric\n",
    "        for i in range(0, len(lipids)):\n",
    "            for j in range(0, i):\n",
    "                counts[i, j] = counts[j, i]\n",
    "            counts[i, i] *= 2\n",
    "        counts /= 2\n",
    "\n",
    "        # print(pd.DataFrame(counts, columns=lipids, index=lipids))\n",
    "\n",
    "        # Normalize by number of each lipid within leaflet\n",
    "        # ROWWISE DIVISION...\n",
    "        normed_counts = np.divide(\n",
    "            counts, raw_baseline, out=np.zeros_like(counts), where=raw_baseline != 0\n",
    "        )\n",
    "        df_normed_counts = pd.DataFrame(normed_counts, columns=lipids, index=lipids)\n",
    "        print(\"# of each lipid around row lipid\\n\", df_normed_counts)\n",
    "\n",
    "        rowwise_sum = np.sum(normed_counts, axis=1).reshape(-1, 1)\n",
    "        # print(np.array2string(rowwise_sum, max_line_width=np.inf))\n",
    "\n",
    "        likelihood_count = np.divide(\n",
    "            normed_counts,\n",
    "            rowwise_sum,\n",
    "            out=np.zeros_like(counts),\n",
    "            where=rowwise_sum != 0,\n",
    "        )\n",
    "\n",
    "        # print(np.array2string(likelihood_count, max_line_width=np.inf))\n",
    "\n",
    "        diff_counts = np.divide(\n",
    "            likelihood_count,\n",
    "            baseline,\n",
    "            out=np.zeros_like(normed_counts),\n",
    "            where=baseline != 0,\n",
    "        )\n",
    "        # df = pd.DataFrame(normed_counts, columns=lipids, index=lipids)\n",
    "        # print(df)\n",
    "\n",
    "        # print(\"DIFF:\")\n",
    "        df_diff = pd.DataFrame(pd.DataFrame(diff_counts, columns=lipids, index=lipids))\n",
    "\n",
    "        df_diff.to_csv(f\"sheets/sim_{sim}_likelihood_{prefix}.csv\")\n",
    "\n",
    "        print(\"Enrichment from likelihood:\\n\", df_diff)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_enrichment = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    with open(\n",
    "        util.analysis_path / f\"{sim}/neighbor_enrichment_leaflet_glo.pickle\", \"rb\"\n",
    "    ) as handle:\n",
    "        neighbor_enrichment[sim] = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8cf045",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_neighbor_analysis(neighbor_enrichment, prefix=\"15A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5522b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    with open(util.analysis_path / f\"{sim}/voronoi_leaflet_glo.pickle\", \"rb\") as handle:\n",
    "        voronoi[sim] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f639a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_neighbor_analysis(voronoi, prefix=\"voronoi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64792c",
   "metadata": {},
   "source": [
    "# Lateral Pressures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5378ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_cubic_np(z, lp, minz=None, maxz=None, maxiter=5000, sym: bool = True):\n",
    "    \"\"\"\n",
    "    Compute the first moment using a cubic piecewise interpolant and Gaussian quadrature\n",
    "    \"\"\"\n",
    "    lp = lp / 1e3  # to convert to piconewtons / nm^2\n",
    "\n",
    "    if sym:\n",
    "        if len(lp) % 2 == 1:\n",
    "            s = int(np.floor(len(lp) / 2))\n",
    "            bot, mid, top = np.split(lp, [s, s + 1])\n",
    "            sym_top = (np.flip(bot) + top) / 2\n",
    "            sym_bot = np.flip(sym_top)\n",
    "            lp = np.hstack((sym_bot, mid, sym_top))\n",
    "        else:\n",
    "            bot, top = np.split(lp, 2)\n",
    "            sym_top = (np.flip(bot) + top) / 2\n",
    "            sym_bot = np.flip(sym_top)\n",
    "            lp = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "    y = lp * z\n",
    "\n",
    "    if minz is None:\n",
    "        minz = min(z)\n",
    "    if maxz is None:\n",
    "        maxz = max(z)\n",
    "\n",
    "    approx = interpolate.interp1d(z, y, kind=\"cubic\")  # interpolating a function\n",
    "    intg = integrate.quadrature(\n",
    "        approx, minz, maxz, maxiter=maxiter\n",
    "    )  # finding the integral over bounds\n",
    "    return intg\n",
    "\n",
    "\n",
    "def zero_cubic_np(z, lp, minz=None, maxz=None, maxiter=5000, sym: bool = True):\n",
    "    \"\"\"\n",
    "    Compute the zeroeth moment using a cubic piecewise interpolant and Gaussian quadrature\n",
    "    \"\"\"\n",
    "    # p = data['LP_(kPA)']/1e15 # to convert to newtons / nm^2\n",
    "    lp = lp / 1e3  # to convert to piconewtons / nm^2\n",
    "\n",
    "    if sym:\n",
    "        if len(lp) % 2 == 1:\n",
    "            s = int(np.floor(len(lp) / 2))\n",
    "            bot, mid, top = np.split(lp, [s, s + 1])\n",
    "            sym_top = (np.flip(bot) + top) / 2\n",
    "            sym_bot = np.flip(sym_top)\n",
    "            lp = np.hstack((sym_bot, mid, sym_top))\n",
    "        else:\n",
    "            bot, top = np.split(lp, 2)\n",
    "            sym_top = (np.flip(bot) + top) / 2\n",
    "            sym_bot = np.flip(sym_top)\n",
    "            lp = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "    if minz is None:\n",
    "        minz = min(z)\n",
    "    if maxz is None:\n",
    "        maxz = max(z)\n",
    "\n",
    "    approx = interpolate.interp1d(z, lp, kind=\"cubic\")  # interpolating a function\n",
    "    intg = integrate.quadrature(\n",
    "        approx, minz, maxz, maxiter=maxiter\n",
    "    )  # finding the integral over bounds\n",
    "    return intg\n",
    "\n",
    "\n",
    "def mean_squared_deviation_np(data: npt.ArrayLike) -> float:\n",
    "    \"\"\"\n",
    "    Compute the mean squared deviation of the data\n",
    "    \"\"\"\n",
    "    return sum(data ** 2) / (data.size - 1)\n",
    "\n",
    "\n",
    "def max_difference(a: npt.ArrayLike, b: npt.ArrayLike):\n",
    "    \"\"\"\n",
    "    Get the max difference between two equal sized arrays\n",
    "    \"\"\"\n",
    "    if a.size != b.size:\n",
    "        raise RuntimeError(\"a and b must be same sized arrays\")\n",
    "    diff = np.abs(a - b)\n",
    "    return np.amax(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3970fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def first_cubic(data, minz=None, maxz=None, maxiter=5000, sym: bool = True):\n",
    "#     \"\"\"\n",
    "#     Compute the first moment using a cubic piecewise interpolant and Gaussian quadrature\n",
    "#     \"\"\"\n",
    "#     x = data[\"z\"]  # in nanometers\n",
    "#     # p = data['LP_(kPA)']/1e15 #to convert to newtons / nm^2\n",
    "#     p = data[\"LP_(kPA)\"].values / 1e3  # to convert to piconewtons / nm^2\n",
    "\n",
    "#     if sym:\n",
    "#         if len(p) % 2 == 1:\n",
    "#             s = int(np.floor(len(p) / 2))\n",
    "#             bot, mid, top = np.split(p, [s, s + 1])\n",
    "#             sym_top = (np.flip(bot) + top) / 2\n",
    "#             sym_bot = np.flip(sym_top)\n",
    "#             p = np.hstack((sym_bot, mid, sym_top))\n",
    "#         else:\n",
    "#             bot, top = np.split(p, 2)\n",
    "#             sym_top = (np.flip(bot) + top) / 2\n",
    "#             sym_bot = np.flip(sym_top)\n",
    "#             p = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "#     y = p * x\n",
    "\n",
    "#     if minz is None:\n",
    "#         minz = min(x)\n",
    "#     if maxz is None:\n",
    "#         maxz = max(x)\n",
    "\n",
    "#     approx = interpolate.interp1d(x, y, kind=\"cubic\")  # interpolating a function\n",
    "#     intg = integrate.quadrature(\n",
    "#         approx, minz, maxz, maxiter=maxiter\n",
    "#     )  # finding the integral over bounds\n",
    "#     return intg\n",
    "\n",
    "\n",
    "# def zero_cubic(data, minz=None, maxz=None, maxiter=5000, sym: bool = True):\n",
    "#     \"\"\"\n",
    "#     Compute the zeroeth moment using a cubic piecewise interpolant and Gaussian quadrature\n",
    "#     \"\"\"\n",
    "#     x = data[\"z\"]  # in nanometers\n",
    "#     # p = data['LP_(kPA)']/1e15 # to convert to newtons / nm^2\n",
    "#     p = data[\"LP_(kPA)\"].values / 1e3  # to convert to piconewtons / nm^2\n",
    "\n",
    "#     if sym:\n",
    "#         if len(p) % 2 == 1:\n",
    "#             s = int(np.floor(len(p) / 2))\n",
    "#             bot, mid, top = np.split(p, [s, s + 1])\n",
    "#             sym_top = (np.flip(bot) + top) / 2\n",
    "#             sym_bot = np.flip(sym_top)\n",
    "#             p = np.hstack((sym_bot, mid, sym_top))\n",
    "#         else:\n",
    "#             bot, top = np.split(p, 2)\n",
    "#             sym_top = (np.flip(bot) + top) / 2\n",
    "#             sym_bot = np.flip(sym_top)\n",
    "#             p = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "#     if minz is None:\n",
    "#         minz = min(x)\n",
    "#     if maxz is None:\n",
    "#         maxz = max(x)\n",
    "\n",
    "#     approx = interpolate.interp1d(x, p, kind=\"cubic\")  # interpolating a function\n",
    "#     intg = integrate.quadrature(\n",
    "#         approx, minz, maxz, maxiter=maxiter\n",
    "#     )  # finding the integral over bounds\n",
    "#     return intg\n",
    "\n",
    "# def mean_squared_deviation(data: pd.DataFrame, var: str = \"Szz\") -> float:\n",
    "#     \"\"\"\n",
    "#     Compute the mean squared deviation of the data\n",
    "#     \"\"\"\n",
    "#     return sum(data[var] ** 2) / (data[var].size - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LStensor import LStensor\n",
    "\n",
    "lateral_pressure = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    fd = Path(util.analysis_path /  f\"{sim}_small/stress_calc/frames/frame{i}.dat0\")\n",
    "    field = LStensor(2)\n",
    "    field.g_loaddata(files=[fd], bAvg=\"avg\")\n",
    "\n",
    "    # stress_tensor = np.empty((20000, field.nz, 9))\n",
    "    lateral_pressure[sim] = np.empty((20000, field.nz, 3))\n",
    "\n",
    "    # 0-20000 frames in each trajectory\n",
    "    for i, j in enumerate(range(1, 20001)):\n",
    "        fd = Path(util.analysis_path / f\"{sim}_small/stress_calc/frames/frame{j}.dat0\")\n",
    "        field = LStensor(2)\n",
    "        field.g_loaddata(files=[fd], bAvg=\"avg\")\n",
    "        stress_tensor = field.data_grid * 100   # Convert to kPa from 10^5 Pa\n",
    "        # Sxx Sxy Sxz Syx Syy Syz Szx Szy Szz\n",
    "        # 0               4               8\n",
    "\n",
    "        pXY = -0.5*(stress_tensor[:,0] + stress_tensor[:,4]).reshape(-1,1)\n",
    "        pN = (-stress_tensor[:,8]).reshape(-1,1)\n",
    "        lp = pXY - pN\n",
    "        z = (np.arange(field.nz) * field.dz - (field.nz - 1) * field.dz / 2).reshape(-1,1)\n",
    "        lateral_pressure[sim][i] = np.hstack((pN, lp, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard first X% for all trajectories\n",
    "discard = 10\n",
    "blocks = np.arange(1, 2**8 + 1, 1)\n",
    "\n",
    "lp_block_var = {}\n",
    "lp_block_sem = {}\n",
    "lp_block_mean = {}\n",
    "for sim in util.simulations:\n",
    "    data = lateral_pressure[sim][:,:, 1]\n",
    "    nT, nZs= data.shape\n",
    "\n",
    "    lp_block_mean[sim] = np.zeros((nZs, len(blocks)))\n",
    "    lp_block_var[sim] = np.zeros((nZs, len(blocks)))\n",
    "    lp_block_sem[sim] = np.zeros((nZs, len(blocks)))\n",
    "    \n",
    "    _, remainder = np.split(data, [int(discard / 100 * len(data))])\n",
    "\n",
    "    lp_block_mean[sim] = util.nd_block_average(remainder, axis=0, func=np.mean, blocks=blocks)\n",
    "    lp_block_var[sim] = util.nd_block_average(remainder, axis=0, func=partial(np.var, ddof=1), blocks=blocks)\n",
    "    lp_block_sem[sim] = util.nd_block_average(remainder, axis=0, func=partial(stats.sem, ddof=1), blocks=blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lateral_pressure[\"1\"][:, :, 1][:, 105]\n",
    "print(len(data))\n",
    "result = np.correlate(data, data, mode='full')\n",
    "plt.plot(result[int(result.size/2):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cf8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in util.simulations:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "    ax.errorbar(np.mean(lateral_pressure[sim], axis=0)[:, 2], lp_block_mean[sim][:,0], yerr=np.sqrt(lp_block_var[sim][:,0]), color=\"b\", linewidth=THIN_LINE,ecolor=\"lightgray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27076071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sim in util.simulations:\n",
    "    # print(sim, lateral_pressure[sim][:,:,1].shape)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "\n",
    "    for i in range(50, 150):\n",
    "        data = lateral_pressure[sim][:,:,1]\n",
    "\n",
    "        ax.plot(\n",
    "            range(len(data[:, i])),\n",
    "            data[:, i], \n",
    "            linewidth=NORMAL_LINE,\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(r\"Frame\")\n",
    "    ax.set_ylabel(r\"Pressure\")\n",
    "    ax.set_title(f\"Sys{sim}:{util.system_names[sim]}\")\n",
    "\n",
    "    # ax.legend(loc=\"upper right\")\n",
    "\n",
    "    # # Shrink current axis by 20%\n",
    "    # box = ax.get_position()\n",
    "    # ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # # Put a legend to the right of the current axis\n",
    "    # ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a436e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures/lp_block_analysis\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lp_corrected_mean_sem = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    nZs, nBlock = lp_block_mean[sim].shape\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))  # sharex=True,\n",
    "\n",
    "    lp_corrected_mean_sem[sim] = np.empty((2, nZs))\n",
    "\n",
    "    for z in range(100,105): #nZs):\n",
    "        # Mean with block size 1\n",
    "        lp_corrected_mean_sem[sim][0, z] = lp_block_mean[sim][z][0] \n",
    "        blocked_sem = lp_block_sem[sim][z]\n",
    "        block_var = lp_block_var[sim][z]\n",
    "\n",
    "        # popt, pcov = curve_fit(\n",
    "        #     correlation_time_sqrt, blocks, blocked_sem / blocked_sem[0]\n",
    "        # )\n",
    "        # lp_corrected_mean_sem[sim][1, z] = blocked_sem[0]* np.sqrt(2*popt[0])\n",
    "        \n",
    "        ax.plot(\n",
    "            np.log2(blocks),\n",
    "            # blocked_sem / blocked_sem[0],\n",
    "            blocks * (block_var / block_var[0]),\n",
    "            linewidth=NORMAL_LINE,\n",
    "            # label=f\"q{q}\",\n",
    "            # color=sns.color_palette(\"colorblind\")[q],\n",
    "            linestyle=\":\",\n",
    "        )\n",
    "\n",
    "        # ax.plot(\n",
    "        #     np.log2(blocks),\n",
    "        #     [correlation_time_sqrt(block, popt) for block in blocks],\n",
    "        #     linewidth=NORMAL_LINE,\n",
    "        #     # color=sns.color_palette(\"colorblind\")[q],\n",
    "        # )\n",
    "\n",
    "    ax.set_xlabel(r\"$log_2$(block)\")\n",
    "    ax.set_ylabel(r\"$\\delta X_b/\\delta X_1$\")\n",
    "    ax.set_title(f\"Sys{sim}:{util.system_names[sim]}\")\n",
    "    # ax.legend(loc=\"upper left\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # fig.savefig(curr_fig_path/f\"{sim}_lp_block_error.png\", format=\"png\")\n",
    "\n",
    "    if show_figs:\n",
    "        plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fafb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 11, figsize=(12, 8), sharex=True, sharey=True)\n",
    "for sim in util.simulations:\n",
    "    ax_index = int(sim) - 1\n",
    "    ax[ax_index].axhline(0, linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "    data = np.mean(lateral_pressure[sim], axis=0)\n",
    "    z = data[:, 2]\n",
    "\n",
    "    ax[ax_index].plot(\n",
    "        data[:,0] * 0.01,\n",
    "        z,\n",
    "        label=\"Normal Stress\",\n",
    "        linewidth=NORMAL_LINE,\n",
    "        linestyle=\"-\",\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "    lateral = data[:,1] * 0.01 # bar\n",
    "\n",
    "    # Symmetrizing\n",
    "    if len(lateral) % 2 == 1:\n",
    "        s = int(np.floor(len(lateral) / 2))\n",
    "        bot, mid, top = np.split(lateral, [s, s + 1])\n",
    "        sym_top = (np.flip(bot) + top) / 2\n",
    "        sym_bot = np.flip(sym_top)\n",
    "        sym_lp = np.hstack((sym_bot, mid, sym_top))\n",
    "    else:\n",
    "        bot, top = np.split(lateral, 2)\n",
    "        sym_top = (np.flip(bot) + top) / 2\n",
    "        sym_bot = np.flip(sym_top)\n",
    "        sym_lp = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "    ax[ax_index].fill_betweenx(z, sym_lp, 0, label=\"Lateral Pressure\", alpha=0.4)\n",
    "\n",
    "    ax[ax_index].set_ylim(-4, 4)\n",
    "    # ax[x,y].ticklabel_format(axis = 'x', style = 'sci', scilimits = (0,0))\n",
    "    ax[ax_index].set_xlabel(\"S or P (bar)\")\n",
    "    ax[ax_index].set_title(f\"{util.system_names[sim]}\", rotation=45)\n",
    "    if ax_index == 0:\n",
    "        ax[ax_index].set_ylabel(\"Z (nm)\")\n",
    "\n",
    "# handles = [\n",
    "#     mlines.Line2D([], [], color=\"black\", linestyle=\":\", label=\"Normal Stress\"),\n",
    "#     mlines.Line2D(\n",
    "#         [],\n",
    "#         [],\n",
    "#         color=\"black\",\n",
    "#         linestyle=\"-\",\n",
    "#         label=\"Lateral Stress\",\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "# plt.legend(handles=handles, bbox_to_anchor=(-2.5, -0.95, 0.8, 0.8), ncol=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig.savefig(curr_fig_path / \"stress.png\", format=\"png\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86a94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = True\n",
    "curr_fig_path = Path(\"Figures\")\n",
    "curr_fig_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 11, figsize=(12, 8), sharex=True, sharey=True)\n",
    "for sim in util.simulations:\n",
    "    ax_index = int(sim) - 1\n",
    "    ax[ax_index].axhline(0, linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "    data = np.mean(lateral_pressure[sim], axis=0)\n",
    "    z = data[:, 2]\n",
    "\n",
    "    lateral = data[:,1] / 1e3 # pN/nm^2\n",
    "    # Symmetrizing\n",
    "    if len(lateral) % 2 == 1:\n",
    "        s = int(np.floor(len(lateral) / 2))\n",
    "        bot, mid, top = np.split(lateral, [s, s + 1])\n",
    "        sym_top = (np.flip(bot) + top) / 2\n",
    "        sym_bot = np.flip(sym_top)\n",
    "        sym_lp = np.hstack((sym_bot, mid, sym_top))\n",
    "    else:\n",
    "        bot, top = np.split(lateral, 2)\n",
    "        sym_top = (np.flip(bot) + top) / 2\n",
    "        sym_bot = np.flip(sym_top)\n",
    "        sym_lp = np.hstack((sym_bot, sym_top))\n",
    "\n",
    "    ax[ax_index].fill_betweenx(z, z*sym_lp, 0, label=\"Lateral Stress\", alpha=0.4)\n",
    "\n",
    "    ax[ax_index].set_ylim(-4, 4)\n",
    "    # ax[x,y].ticklabel_format(axis = 'x', style = 'sci', scilimits = (0,0))\n",
    "    ax[ax_index].set_xlabel(\"z L_p (pN/nm)\")\n",
    "    ax[ax_index].set_title(f\"{util.system_names[sim]}\", rotation=45)\n",
    "    if ax_index == 0:\n",
    "        ax[ax_index].set_ylabel(\"Z (nm)\")\n",
    "\n",
    "# handles = [\n",
    "#     mlines.Line2D([], [], color=\"black\", linestyle=\":\", label=\"Normal Stress\"),\n",
    "#     mlines.Line2D(\n",
    "#         [],\n",
    "#         [],\n",
    "#         color=\"black\",\n",
    "#         linestyle=\"-\",\n",
    "#         label=\"Lateral Stress\",\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "# plt.legend(handles=handles, bbox_to_anchor=(-2.5, -0.95, 0.8, 0.8), ncol=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(curr_fig_path / \"first_mom_integrand.png\", format=\"png\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cubic_dat = {}\n",
    "z_cubic_dat = {}\n",
    "msd_dat = {}\n",
    "\n",
    "for sim in util.simulations:\n",
    "    try:\n",
    "        data = np.mean(lateral_pressure[sim], axis=0)\n",
    "\n",
    "        z = data[:, 2]\n",
    "        lp = data[:, 1]\n",
    "        szz = data[:, 0]\n",
    "\n",
    "        fcd = first_cubic_np(z, lp)\n",
    "        f_cubic_dat[sim] = (\n",
    "            first_cubic_np(z, lp, maxz=0)[0] - first_cubic_np(z, lp, minz=0)[0]\n",
    "        ) / 2\n",
    "        # print(first_cubic(z, lp, minz=0)[0], first_cubic(z, lp, maxz=0)[0])\n",
    "\n",
    "        zcd = zero_cubic_np(z, lp)\n",
    "        z_cubic_dat[sim] = zero_cubic_np(z, lp)[0]\n",
    "\n",
    "        msd = mean_squared_deviation_np(szz)\n",
    "        msd_dat[sim] = msd\n",
    "        print(\n",
    "            f\"{util.system_names[sim]}\\n\" f\"   Zero Moment (pN/nm): {zcd}\\n\",\n",
    "            f\"     First Moment (pN): {fcd}\\n\",\n",
    "            f\"Monlayer First Moment (pN): {f_cubic_dat[sim]} {first_cubic_np(z, lp, maxz=0)[0]} {first_cubic_np(z, lp, minz=0)[0]}\\n\",\n",
    "            f\"           MSD (kPa^2): {msd}\\n\",\n",
    "            f\" Upper Leaflet Tension: {zero_cubic_np(z, lp, minz=0)}\\n\",\n",
    "            f\" Lower Leaflet Tension: {zero_cubic_np(z, lp, maxz=0)}\\n\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"{util.system_names[sim]}\\n\" f\"{e}\\n\",\n",
    "        )\n",
    "np.save(\"f_cubic_dat.npy\", f_cubic_dat)\n",
    "np.save(\"z_cubic_dat.npy\", z_cubic_dat)\n",
    "np.save(\"msd_dat.npy\", msd_dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_cubic_dat = {}\n",
    "# z_cubic_dat = {}\n",
    "# msd_dat = {}\n",
    "\n",
    "# for sim in util.simulations:\n",
    "#     file = util.analysis_path / f\"{sim}_small/stress_calc/lateral_pressure.csv\"\n",
    "\n",
    "#     try:\n",
    "#         data = pd.read_csv(file)\n",
    "\n",
    "#         fcd = first_cubic(data)\n",
    "#         f_cubic_dat[sim] = (\n",
    "#             first_cubic(data, maxz=0)[0] - first_cubic(data, minz=0)[0]\n",
    "#         ) / 2\n",
    "#         # print(first_cubic(data, minz=0)[0], first_cubic(data, maxz=0)[0])\n",
    "\n",
    "#         zcd = zero_cubic(data)\n",
    "#         z_cubic_dat[sim] = zero_cubic(data)[0]\n",
    "\n",
    "#         msd = mean_squared_deviation(data, \"Szz\")\n",
    "#         msd_dat[sim] = msd\n",
    "#         print(\n",
    "#             f\"{util.system_names[sim]}\\n\" f\"   Zero Moment (pN/nm): {zcd}\\n\",\n",
    "#             f\"     First Moment (pN): {fcd}\\n\",\n",
    "#             f\"Monlayer First Moment (pN): {f_cubic_dat[sim]}\\n\",\n",
    "#             f\"           MSD (kPa^2): {msd}\\n\",\n",
    "#             f\" Upper Leaflet Tension: {zero_cubic(data, minz=0)}\\n\",\n",
    "#             f\" Lower Leaflet Tension: {zero_cubic(data, maxz=0)}\\n\",\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(\n",
    "#             f\"{util.system_names[sim]}\\n\" f\"{e}\\n\",\n",
    "#         )\n",
    "# np.save(\"f_cubic_dat.npy\", f_cubic_dat)\n",
    "# np.save(\"z_cubic_dat.npy\", z_cubic_dat)\n",
    "# np.save(\"msd_dat.npy\", msd_dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.axhline(0, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "ax.scatter(\n",
    "    np.arange(0, 2),\n",
    "    [z_cubic_dat[k] for k in [\"8\", \"9\"]],\n",
    "    label=\"+CDL\",\n",
    "    marker=\"s\",\n",
    "    s=6**2,\n",
    ")\n",
    "ax.scatter(\n",
    "    np.arange(0, 2),\n",
    "    [z_cubic_dat[k] for k in [\"10\", \"11\"]],\n",
    "    label=\"-CDL\",\n",
    "    s=8**2,\n",
    ")\n",
    "\n",
    "# ax.set_ylim(-2, 4)\n",
    "ax.set_ylabel(\"0th mom. (pN/nm)\")\n",
    "# ax.tick_params(axis = 'y', labelcolor = 'darkorange')\n",
    "# ax.set_xlim(0, 25)\n",
    "ax.set_xticks([0, 1], labels=[\"PO\", \"DO\"])\n",
    "# plt.xscale('log')\n",
    "ax.set_xlabel(\"Saturation\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "save_fig(fig, \"Figures/zero_moment\")\n",
    "\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904609dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# ax.axhline(0, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "ax.scatter(\n",
    "    np.arange(0, 2),\n",
    "    [f_cubic_dat[k] for k in [\"8\", \"9\"]],\n",
    "    label=\"+CDL\",\n",
    "    marker=\"s\",\n",
    "    s=6**2,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.scatter(\n",
    "    np.arange(0, 2),\n",
    "    [f_cubic_dat[k] for k in [\"10\", \"11\"]],\n",
    "    label=\"-CDL\",\n",
    "    s=8**2,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "# ax.set_ylim(-2, 4)\n",
    "ax.set_ylabel(\"1st mom. (pN)\")\n",
    "# ax.tick_params(axis = 'y', labelcolor = 'darkorange')\n",
    "# ax.set_xlim(0, 25)\n",
    "ax.set_xticks([0, 1], labels=[\"PO\", \"DO\"])\n",
    "# plt.xscale('log')\n",
    "ax.set_xlabel(\"Saturation\")\n",
    "\n",
    "plt.legend(loc=\"center\")\n",
    "plt.tight_layout()\n",
    "save_fig(fig, \"Figures/first_moment\")\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63905e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# ax.axhline(0, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "ax.scatter(\n",
    "    np.arange(1, 12),\n",
    "    [f_cubic_dat[k] for k in util.simulations],\n",
    "    marker=\"s\",\n",
    "    s=6**2,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "# ax.set_ylim(-2, 4)\n",
    "ax.set_ylabel(\"1st mom. (pN)\")\n",
    "# ax.tick_params(axis = 'y', labelcolor = 'darkorange')\n",
    "ax.set_xlabel(\"System\")\n",
    "ax.set_xticks(np.arange(1, 12, 1))\n",
    "\n",
    "# plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "save_fig(fig, \"Figures/first_moment_all\")\n",
    "plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfcaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in util.simulations:\n",
    "    print(f\"System {sim} c0: {f_cubic_dat[sim]/(kc_mean_std[int(sim)-1][0] * 4.18336647): 0.3f} nm^-1;\", 1 / (f_cubic_dat[sim]/(kc_mean_std[int(sim)-1][0] * 4.18336647)), \"nm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.loadtxt(\"sheets/kb.csv\", delimiter=\",\")\n",
    "# print(data)\n",
    "\n",
    "\n",
    "# tdata = np.empty((5, 2))\n",
    "# for i, v in enumerate([10, 9, 3, 4, 5]):\n",
    "#     tdata[i] = data[v]\n",
    "#     print(util.system_names[str(v + 1)])\n",
    "# print(tdata)\n",
    "# names = [f\"System {i}\" for i in range(1, 6)]\n",
    "# print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd012b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 5))  # sharex=True,\n",
    "# ax.bar(names, tdata[:, 0], yerr=tdata[:, 1])\n",
    "# ax.set_ylabel(r\"Bending modulus ($k_BT$)\")\n",
    "\n",
    "# save_fig(fig, f\"Figures/temp_kb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e100c11",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f500b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ca4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in f_cubic_dat.items():\n",
    "    print(f\"{k}\t{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ca4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in f_cubic_dat.items():\n",
    "    print(f\"{k}\t{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a99f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda",
   "language": "python",
   "name": "mda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "758e6dc3310fc4113a14db5c9af04d510b7dde461179a1a88c244d629ae14de1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
